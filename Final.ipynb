{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1c58a4-c4c0-41fd-aa81-238204abb88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RL Controller implementation...\n",
      "Got reference trajectory with shape: (7201, 1)\n",
      "Training RL controller on cpu...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import random\n",
    "import os\n",
    "from collections import deque\n",
    "\n",
    "# Fix random state for consistency\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Simplified network architecture - removed CNN for speed\n",
    "class FastDQNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hidden_size=64):\n",
    "        super(FastDQNetwork, self).__init__()\n",
    "        \n",
    "        # Simpler LSTM architecture\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=1,  # Single feature input\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,  # Reduced from 2 to 1\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Simpler Q-value prediction layers\n",
    "        self.q_layers = nn.Sequential(\n",
    "            nn.Linear(hidden_size, action_size)  # Direct mapping\n",
    "        )\n",
    "    \n",
    "    def forward(self, state):\n",
    "        # Handle different input shapes efficiently\n",
    "        if isinstance(state, np.ndarray):\n",
    "            state = torch.FloatTensor(state)\n",
    "            \n",
    "        batch_size = state.size(0) if state.dim() > 1 else 1\n",
    "        seq_len = state.size(-1) if state.dim() > 1 else state.size(0)\n",
    "        \n",
    "        # Reshape to [batch_size, seq_len, features]\n",
    "        if state.dim() == 1:\n",
    "            # Single sample: [seq_len] -> [1, seq_len, 1]\n",
    "            x = state.view(1, seq_len, 1)\n",
    "        elif state.dim() == 2:\n",
    "            # Batch: [batch_size, seq_len] -> [batch_size, seq_len, 1]\n",
    "            x = state.view(batch_size, seq_len, 1)\n",
    "        else:\n",
    "            # Already in correct shape\n",
    "            x = state\n",
    "            \n",
    "        # LSTM\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        last_out = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Get Q-values for each action\n",
    "        q_values = self.q_layers(last_out)\n",
    "        \n",
    "        return q_values\n",
    "\n",
    "# Optimized Replay Buffer with numpy arrays instead of deque operations\n",
    "class FastReplayBuffer:\n",
    "    def __init__(self, capacity=10000, state_size=50):\n",
    "        self.capacity = capacity\n",
    "        self.state_size = state_size\n",
    "        \n",
    "        # Pre-allocate memory for all experiences\n",
    "        self.states = np.zeros((capacity, state_size), dtype=np.float32)\n",
    "        self.next_states = np.zeros((capacity, state_size), dtype=np.float32)\n",
    "        self.actions = np.zeros(capacity, dtype=np.int64)\n",
    "        self.rewards = np.zeros(capacity, dtype=np.float32)\n",
    "        self.dones = np.zeros(capacity, dtype=np.float32)\n",
    "        \n",
    "        self.position = 0\n",
    "        self.size = 0\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        # Store experience\n",
    "        self.states[self.position] = state\n",
    "        self.actions[self.position] = action\n",
    "        self.rewards[self.position] = reward\n",
    "        self.next_states[self.position] = next_state\n",
    "        self.dones[self.position] = float(done)\n",
    "        \n",
    "        # Update position and size\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "        self.size = min(self.size + 1, self.capacity)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        # Sample random indices\n",
    "        indices = np.random.choice(self.size, batch_size, replace=False)\n",
    "        \n",
    "        # Return experiences as tensors\n",
    "        return (\n",
    "            torch.FloatTensor(self.states[indices]),\n",
    "            torch.LongTensor(self.actions[indices]),\n",
    "            torch.FloatTensor(self.rewards[indices]),\n",
    "            torch.FloatTensor(self.next_states[indices]),\n",
    "            torch.FloatTensor(self.dones[indices])\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "# NEW: System model for simulation\n",
    "class SystemDynamicsModel:\n",
    "    def __init__(self, inertia=1.0, damping=0.1, dt=0.1):\n",
    "        \"\"\"Simple dynamic system model (e.g., motor or physical system)\n",
    "        \n",
    "        Args:\n",
    "            inertia: System inertia coefficient\n",
    "            damping: System damping coefficient\n",
    "            dt: Time step for discrete simulation\n",
    "        \"\"\"\n",
    "        self.inertia = inertia\n",
    "        self.damping = damping\n",
    "        self.dt = dt\n",
    "        \n",
    "        # System state\n",
    "        self.position = 0.0\n",
    "        self.velocity = 0.0\n",
    "        \n",
    "    def reset(self, position=0.0, velocity=0.0):\n",
    "        \"\"\"Reset system to initial state\"\"\"\n",
    "        self.position = position\n",
    "        self.velocity = velocity\n",
    "        return self.position\n",
    "        \n",
    "    def step(self, control_force):\n",
    "        \"\"\"Apply control force and update system state\n",
    "        \n",
    "        Simple second-order dynamics model: m*a + b*v = F\n",
    "        Where:\n",
    "            m = inertia\n",
    "            b = damping coefficient\n",
    "            F = control force\n",
    "        \"\"\"\n",
    "        # Calculate acceleration from control force and current state\n",
    "        acceleration = (control_force - self.damping * self.velocity) / self.inertia\n",
    "        \n",
    "        # Update velocity and position using simple Euler integration\n",
    "        self.velocity += acceleration * self.dt\n",
    "        self.position += self.velocity * self.dt\n",
    "        \n",
    "        return self.position\n",
    "\n",
    "# NEW: Sensor interface for real-world applications\n",
    "class SensorInterface:\n",
    "    def __init__(self, use_simulation=True, sensor_noise=0.01):\n",
    "        \"\"\"Sensor interface that can read from simulation or real hardware\n",
    "        \n",
    "        Args:\n",
    "            use_simulation: If True, use simulated data. If False, read from real sensors.\n",
    "            sensor_noise: Amount of noise to add to simulated sensor readings\n",
    "        \"\"\"\n",
    "        self.use_simulation = use_simulation\n",
    "        self.sensor_noise = sensor_noise\n",
    "        \n",
    "        # If not using simulation, set up hardware communication\n",
    "        if not use_simulation:\n",
    "            try:\n",
    "                # This would be replaced with actual hardware setup code\n",
    "                # e.g., import serial, GPIO setup, etc.\n",
    "                print(\"Setting up hardware communication...\")\n",
    "                # self.serial_port = serial.Serial('/dev/ttyUSB0', 9600)\n",
    "            except Exception as e:\n",
    "                print(f\"Hardware setup failed: {e}\")\n",
    "                print(\"Falling back to simulation mode\")\n",
    "                self.use_simulation = True\n",
    "    \n",
    "    def read_position(self, simulated_position=None):\n",
    "        \"\"\"Read current position from sensor or simulation\"\"\"\n",
    "        if self.use_simulation:\n",
    "            # Add noise to simulated position\n",
    "            return simulated_position + np.random.normal(0, self.sensor_noise)\n",
    "        else:\n",
    "            # This would be replaced with actual sensor reading code\n",
    "            # e.g., self.serial_port.write(b'READ_POS\\n')\n",
    "            # return float(self.serial_port.readline())\n",
    "            return 0.0  # Placeholder\n",
    "\n",
    "# NEW: Actuator interface for real-world applications\n",
    "class ActuatorInterface:\n",
    "    def __init__(self, use_simulation=True, control_min=-1.0, control_max=1.0):\n",
    "        \"\"\"Actuator interface that can send commands to simulation or real hardware\n",
    "        \n",
    "        Args:\n",
    "            use_simulation: If True, return values for simulation. If False, send to real actuators.\n",
    "            control_min: Minimum control signal value\n",
    "            control_max: Maximum control signal value\n",
    "        \"\"\"\n",
    "        self.use_simulation = use_simulation\n",
    "        self.control_min = control_min\n",
    "        self.control_max = control_max\n",
    "        \n",
    "        # If not using simulation, set up hardware communication\n",
    "        if not use_simulation:\n",
    "            try:\n",
    "                # This would be replaced with actual hardware setup code\n",
    "                print(\"Setting up actuator communication...\")\n",
    "                # self.serial_port = serial.Serial('/dev/ttyUSB1', 9600)\n",
    "            except Exception as e:\n",
    "                print(f\"Actuator setup failed: {e}\")\n",
    "                print(\"Falling back to simulation mode\")\n",
    "                self.use_simulation = True\n",
    "    \n",
    "    def send_control(self, control_signal):\n",
    "        \"\"\"Send control signal to actuator or return for simulation\"\"\"\n",
    "        # Clip control signal to valid range\n",
    "        control_signal = np.clip(control_signal, self.control_min, self.control_max)\n",
    "        \n",
    "        if self.use_simulation:\n",
    "            return control_signal\n",
    "        else:\n",
    "            # This would be replaced with actual actuator control code\n",
    "            # e.g., self.serial_port.write(f'SET_PWM {control_signal}\\n')\n",
    "            print(f\"Sending control signal: {control_signal}\")\n",
    "            return control_signal\n",
    "\n",
    "# Modified: RL Controller Environment (previously TrajectoryEnvironment)\n",
    "class RLControlEnvironment:\n",
    "    def __init__(self, reference_trajectory, window_size=50, control_discretization=20,\n",
    "                 use_simulation=True, control_effort_weight=0.1):\n",
    "        \"\"\"Environment for the RL Controller\n",
    "        \n",
    "        Args:\n",
    "            reference_trajectory: Target trajectory to follow\n",
    "            window_size: Size of state window (recent positions and setpoints)\n",
    "            control_discretization: Number of discrete control actions\n",
    "            use_simulation: If True, use simulated system. If False, use real hardware.\n",
    "            control_effort_weight: Weight of control effort term in reward (λ)\n",
    "        \"\"\"\n",
    "        self.reference_trajectory = reference_trajectory\n",
    "        self.window_size = window_size\n",
    "        self.use_simulation = use_simulation\n",
    "        self.control_effort_weight = control_effort_weight\n",
    "        \n",
    "        # Create discrete action space (control signals)\n",
    "        self.control_range = [-1.0, 1.0]  # Normalized control range\n",
    "        self.action_values = np.linspace(\n",
    "            self.control_range[0], \n",
    "            self.control_range[1], \n",
    "            control_discretization\n",
    "        )\n",
    "        self.action_size = len(self.action_values)\n",
    "        \n",
    "        # State is the window of previous values and setpoints\n",
    "        # [positions, setpoints] concatenated\n",
    "        self.state_size = window_size\n",
    "        \n",
    "        # Initialize system model, sensors, and actuators\n",
    "        self.system = SystemDynamicsModel()\n",
    "        self.sensor = SensorInterface(use_simulation=use_simulation)\n",
    "        self.actuator = ActuatorInterface(use_simulation=use_simulation)\n",
    "        \n",
    "        # Current position in the reference trajectory\n",
    "        self.current_idx = window_size\n",
    "        self.max_idx = len(reference_trajectory) - 1\n",
    "        \n",
    "        # History of positions and controls\n",
    "        self.position_history = np.zeros(window_size)\n",
    "        self.control_history = np.zeros(window_size)\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Reset environment to starting point\"\"\"\n",
    "        self.current_idx = self.window_size\n",
    "        self.system.reset()\n",
    "        \n",
    "        # Reset history\n",
    "        self.position_history = np.zeros(self.window_size)\n",
    "        self.control_history = np.zeros(self.window_size)\n",
    "        \n",
    "        # Initial state combines position history and setpoint trajectory\n",
    "        # For simplicity, we'll just use the position history as the state\n",
    "        state = self.position_history.reshape(-1)\n",
    "        return state\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Take control action and return new state, reward, done\"\"\"\n",
    "        # Get the control signal corresponding to this action\n",
    "        control_signal = self.action_values[action]\n",
    "        \n",
    "        # Send control signal to actuator\n",
    "        applied_control = self.actuator.send_control(control_signal)\n",
    "        \n",
    "        # Apply control to system (simulation or real)\n",
    "        if self.use_simulation:\n",
    "            # Update system with control input\n",
    "            new_position = self.system.step(applied_control)\n",
    "            \n",
    "            # Read position from sensor (with noise)\n",
    "            measured_position = self.sensor.read_position(new_position)\n",
    "        else:\n",
    "            # In real-world mode, just read the sensor after applying control\n",
    "            # The control signal has already been sent by the actuator interface\n",
    "            measured_position = self.sensor.read_position()\n",
    "        \n",
    "        # Get current setpoint from reference trajectory\n",
    "        current_setpoint = self.reference_trajectory[self.current_idx][0]\n",
    "        \n",
    "        # Calculate tracking error\n",
    "        tracking_error = abs(measured_position - current_setpoint)\n",
    "        \n",
    "        # Calculate control effort penalty\n",
    "        control_effort = abs(control_signal)\n",
    "        \n",
    "        # Calculate reward: -(tracking error) - λ(control effort)\n",
    "        reward = -tracking_error - self.control_effort_weight * control_effort\n",
    "        \n",
    "        # Update histories\n",
    "        self.position_history = np.append(self.position_history[1:], measured_position)\n",
    "        self.control_history = np.append(self.control_history[1:], control_signal)\n",
    "        \n",
    "        # Move to next setpoint\n",
    "        self.current_idx += 1\n",
    "        done = self.current_idx >= self.max_idx\n",
    "        \n",
    "        # Get new state\n",
    "        if not done:\n",
    "            # State is the history of positions\n",
    "            next_state = self.position_history.reshape(-1)\n",
    "        else:\n",
    "            next_state = np.zeros(self.window_size)  # Default state when done\n",
    "            \n",
    "        return next_state, reward, done\n",
    "    \n",
    "    def get_current_setpoint(self):\n",
    "        \"\"\"Get the current target setpoint\"\"\"\n",
    "        if self.current_idx < len(self.reference_trajectory):\n",
    "            return self.reference_trajectory[self.current_idx][0]\n",
    "        return None\n",
    "\n",
    "# Optimized DQN Agent - Minimal changes for control application\n",
    "class FastDQNAgent:\n",
    "    def __init__(self, state_size, action_size, hidden_size=64, device='cpu'):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.device = device\n",
    "        \n",
    "        # Hyperparameters - increased learning rate and batch size for faster convergence\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.97  # Faster decay\n",
    "        self.learning_rate = 0.003  # Increased from 0.001\n",
    "        self.batch_size = 128  # Increased from 64\n",
    "        self.update_target_every = 5  # More frequent updates\n",
    "        \n",
    "        # Networks\n",
    "        self.q_network = FastDQNetwork(state_size, action_size, hidden_size).to(device)\n",
    "        self.target_network = FastDQNetwork(state_size, action_size, hidden_size).to(device)\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "        self.target_network.eval()  # target network in eval mode\n",
    "        \n",
    "        # Optimizer with higher learning rate\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        # Memory\n",
    "        self.memory = FastReplayBuffer(capacity=10000, state_size=state_size)\n",
    "        \n",
    "        # Tracking\n",
    "        self.episode_count = 0\n",
    "        \n",
    "        # Create evaluation mode flag to avoid unnecessary computation\n",
    "        self.training_mode = True\n",
    "    \n",
    "    def select_action(self, state, training=True):\n",
    "        \"\"\"Select action using epsilon-greedy policy\"\"\"\n",
    "        self.training_mode = training\n",
    "        \n",
    "        if training and random.random() < self.epsilon:\n",
    "            # Exploration: random action\n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        # Exploitation: best action from Q-network\n",
    "        with torch.no_grad():  # Ensure we don't compute gradients\n",
    "            # Convert to tensor if it's a numpy array\n",
    "            if isinstance(state, np.ndarray):\n",
    "                state = torch.FloatTensor(state)\n",
    "            \n",
    "            # Add batch dimension if needed\n",
    "            if state.dim() == 1:\n",
    "                state = state.unsqueeze(0)  # [L] -> [1, L]\n",
    "                \n",
    "            # Add channel dimension if needed\n",
    "            if state.dim() == 2 and state.size(1) != 1:\n",
    "                state = state.unsqueeze(2)  # [B, L] -> [B, L, 1]\n",
    "                \n",
    "            state = state.to(self.device)\n",
    "            q_values = self.q_network(state)\n",
    "            return torch.argmax(q_values).item()\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Train on a batch from replay memory\"\"\"\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return 0  # Not enough samples\n",
    "        \n",
    "        # Sample batch\n",
    "        states, actions, rewards, next_states, dones = self.memory.sample(self.batch_size)\n",
    "        \n",
    "        # Move to device\n",
    "        states = states.to(self.device)\n",
    "        next_states = next_states.to(self.device)\n",
    "        actions = actions.to(self.device)\n",
    "        rewards = rewards.to(self.device)\n",
    "        dones = dones.to(self.device)\n",
    "        \n",
    "        # Get current Q values - more efficient indexing\n",
    "        current_q = self.q_network(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        # Get next Q values - more efficient with no_grad\n",
    "        with torch.no_grad():\n",
    "            # Double DQN\n",
    "            next_actions = torch.argmax(self.q_network(next_states), dim=1)\n",
    "            next_q = self.target_network(next_states).gather(1, next_actions.unsqueeze(1)).squeeze(1)\n",
    "            \n",
    "            # Apply terminal state masking and calculate targets\n",
    "            target_q = rewards + (1 - dones) * self.gamma * next_q\n",
    "        \n",
    "        # Calculate loss and optimize\n",
    "        loss = nn.MSELoss()(current_q, target_q)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Gradient clipping to prevent exploding gradients\n",
    "        nn.utils.clip_grad_norm_(self.q_network.parameters(), 1.0)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    def update_target_network(self):\n",
    "        \"\"\"Update target network weights with soft update instead of hard copy\"\"\"\n",
    "        tau = 0.1  # Soft update parameter\n",
    "        for target_param, param in zip(self.target_network.parameters(), self.q_network.parameters()):\n",
    "            target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
    "    \n",
    "    def decay_epsilon(self):\n",
    "        \"\"\"Decay exploration rate\"\"\"\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "# Get data - similar to original code\n",
    "def get_data(file_path=\"Trajectory2.csv\"):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Check columns\n",
    "        if 'x_Traject' in df.columns:\n",
    "            data = df['x_Traject'].values.reshape(-1, 1)\n",
    "        else:\n",
    "            # No header? Let's try again\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            data = df.values\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Couldn't load data: {e}\")\n",
    "        print(\"Using synthetic data instead\")\n",
    "        \n",
    "        # Make fake trajectory data - temperature setpoint scenario\n",
    "        t = np.linspace(0, 1, 7201)\n",
    "        data = np.zeros((len(t), 1))\n",
    "        \n",
    "        # Let's make something interesting with segments\n",
    "        data[:1000] = 45.0  # Starting temperature\n",
    "        \n",
    "        # Ramp up\n",
    "        for i in range(1000, 3000):\n",
    "            progress = (i - 1000) / 2000\n",
    "            data[i] = 45.0 + progress * (70.0 - 45.0)\n",
    "            \n",
    "        # Hold temp\n",
    "        data[3000:5000] = 70.0\n",
    "        \n",
    "        # Ramp down\n",
    "        for i in range(5000, 6000):\n",
    "            progress = (i - 5000) / 1000\n",
    "            data[i] = 70.0 - progress * (70.0 - 50.0)\n",
    "            \n",
    "        # Final hold\n",
    "        data[6000:] = 50.0\n",
    "        \n",
    "        # Add a bit of noise to make it realistic\n",
    "        data += np.random.normal(0, 0.1, size=data.shape)\n",
    "        \n",
    "    return data.astype(np.float32)  # Cast to float32 for faster tensor operations\n",
    "\n",
    "# Modified: Training function for the RL controller\n",
    "def train_rl_controller(env, agent, episodes=100):\n",
    "    \"\"\"Train the controller agent for the specified number of episodes\"\"\"\n",
    "    rewards_history = []\n",
    "    loss_history = []\n",
    "    tracking_errors = []\n",
    "    control_efforts = []\n",
    "    \n",
    "    # Use mini-batches for faster training\n",
    "    for episode in range(episodes):\n",
    "        # Reset environment\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        episode_losses = []\n",
    "        episode_errors = []\n",
    "        episode_efforts = []\n",
    "        done = False\n",
    "        \n",
    "        # Initialize batch tracking\n",
    "        steps = 0\n",
    "        update_frequency = 4  # Update every N steps instead of every step\n",
    "        \n",
    "        while not done:\n",
    "            # Select and take action\n",
    "            action = agent.select_action(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            \n",
    "            # Calculate tracking error and control effort for logging\n",
    "            current_position = env.position_history[-1]\n",
    "            current_setpoint = env.get_current_setpoint()\n",
    "            control_signal = env.action_values[action]\n",
    "            \n",
    "            tracking_error = abs(current_position - current_setpoint)\n",
    "            control_effort = abs(control_signal)\n",
    "            \n",
    "            episode_errors.append(tracking_error)\n",
    "            episode_efforts.append(control_effort)\n",
    "            \n",
    "            # Store in memory\n",
    "            agent.memory.add(state, action, reward, next_state, done)\n",
    "            \n",
    "            # Move to next state\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "            \n",
    "            # Train the network less frequently\n",
    "            if steps % update_frequency == 0:\n",
    "                loss = agent.train()\n",
    "                if loss > 0:\n",
    "                    episode_losses.append(loss)\n",
    "        \n",
    "        # Update target network periodically using soft updates\n",
    "        agent.update_target_network()\n",
    "        \n",
    "        # Decay exploration rate\n",
    "        agent.decay_epsilon()\n",
    "        \n",
    "        # Track metrics\n",
    "        rewards_history.append(total_reward)\n",
    "        if episode_losses:\n",
    "            loss_history.append(np.mean(episode_losses))\n",
    "        else:\n",
    "            loss_history.append(0)\n",
    "        tracking_errors.append(np.mean(episode_errors))\n",
    "        control_efforts.append(np.mean(episode_efforts))\n",
    "        \n",
    "        # Print progress\n",
    "        if (episode + 1) % 5 == 0:  # Less frequent logging\n",
    "            print(f\"Episode {episode+1}/{episodes} - Reward: {total_reward:.4f}, \"\n",
    "                  f\"Loss: {np.mean(episode_losses) if episode_losses else 0:.4f}, Epsilon: {agent.epsilon:.4f}, \"\n",
    "                  f\"Mean Error: {np.mean(episode_errors):.4f}, Mean Control: {np.mean(episode_efforts):.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'rewards': rewards_history,\n",
    "        'losses': loss_history,\n",
    "        'tracking_errors': tracking_errors,\n",
    "        'control_efforts': control_efforts\n",
    "    }\n",
    "\n",
    "# Modified: Evaluate the trained controller\n",
    "def evaluate_controller(env, agent, scaler=None):\n",
    "    \"\"\"Evaluate the control performance on the reference trajectory\"\"\"\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    # Create arrays to store results\n",
    "    positions = []\n",
    "    setpoints = []\n",
    "    control_signals = []\n",
    "    \n",
    "    # Set evaluation mode\n",
    "    agent.training_mode = False\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        while not done:\n",
    "            # Select best action (no exploration)\n",
    "            action = agent.select_action(state, training=False)\n",
    "            \n",
    "            # Get setpoint before step\n",
    "            current_setpoint = env.get_current_setpoint()\n",
    "            \n",
    "            # Take step\n",
    "            next_state, _, done = env.step(action)\n",
    "            \n",
    "            # Record results\n",
    "            positions.append(env.position_history[-1])  # Last position\n",
    "            setpoints.append(current_setpoint)\n",
    "            control_signals.append(env.action_values[action])\n",
    "            \n",
    "            # Update state\n",
    "            state = next_state\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    positions = np.array(positions)\n",
    "    setpoints = np.array(setpoints)\n",
    "    control_signals = np.array(control_signals)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    tracking_error = np.mean(np.abs(positions - setpoints))\n",
    "    control_effort = np.mean(np.abs(control_signals))\n",
    "    \n",
    "    print(f\"Evaluation Results:\")\n",
    "    print(f\"Mean Tracking Error: {tracking_error:.4f}\")\n",
    "    print(f\"Mean Control Effort: {control_effort:.4f}\")\n",
    "    \n",
    "    # Rescale if scaler is provided\n",
    "    if scaler is not None:\n",
    "        positions = scaler.inverse_transform(positions.reshape(-1, 1)).flatten()\n",
    "        setpoints = scaler.inverse_transform(np.array(setpoints).reshape(-1, 1)).flatten()\n",
    "    \n",
    "    return {\n",
    "        'positions': positions,\n",
    "        'setpoints': setpoints,\n",
    "        'control_signals': control_signals,\n",
    "        'tracking_error': tracking_error,\n",
    "        'control_effort': control_effort\n",
    "    }\n",
    "\n",
    "# Create enhanced visualizations for controller performance\n",
    "def create_controller_visualizations(results, training_metrics=None):\n",
    "    \"\"\"Create visualizations for the controller performance\"\"\"\n",
    "    # Set up the figure with a custom layout\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    grid = gridspec.GridSpec(3, 1, height_ratios=[2, 1, 1])\n",
    "    \n",
    "    # Extract data from results\n",
    "    positions = results['positions']\n",
    "    setpoints = results['setpoints']\n",
    "    control_signals = results['control_signals']\n",
    "    \n",
    "    # First plot - control performance (position vs setpoint)\n",
    "    perf_ax = plt.subplot(grid[0])\n",
    "    time_steps = np.arange(len(positions))\n",
    "    \n",
    "    perf_ax.plot(time_steps, setpoints, 'r--', linewidth=2, label='Setpoint')\n",
    "    perf_ax.plot(time_steps, positions, 'b-', linewidth=1.5, label='System Position')\n",
    "    \n",
    "    perf_ax.set_title('Control System Performance', fontsize=14)\n",
    "    perf_ax.set_xlabel('Time Steps', fontsize=12)\n",
    "    perf_ax.set_ylabel('Position', fontsize=12)\n",
    "    perf_ax.grid(True)\n",
    "    perf_ax.legend()\n",
    "    \n",
    "    # Second plot - control signals\n",
    "    control_ax = plt.subplot(grid[1])\n",
    "    control_ax.plot(time_steps, control_signals, 'g-', linewidth=1.5)\n",
    "    control_ax.set_title('Control Signals', fontsize=14)\n",
    "    control_ax.set_xlabel('Time Steps', fontsize=12)\n",
    "    control_ax.set_ylabel('Control Signal', fontsize=12)\n",
    "    control_ax.grid(True)\n",
    "    \n",
    "    # Third plot - tracking error\n",
    "    error_ax = plt.subplot(grid[2])\n",
    "    tracking_error = np.abs(positions - setpoints)\n",
    "    error_ax.plot(time_steps, tracking_error, 'r-', linewidth=1.5)\n",
    "    error_ax.set_title('Tracking Error', fontsize=14)\n",
    "    error_ax.set_xlabel('Time Steps', fontsize=12)\n",
    "    error_ax.set_ylabel('Error', fontsize=12)\n",
    "    error_ax.grid(True)\n",
    "    \n",
    "    # If training metrics are provided, create additional plots\n",
    "    if training_metrics:\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        grid2 = gridspec.GridSpec(2, 2)\n",
    "        \n",
    "        # Plot rewards\n",
    "        rewards_ax = plt.subplot(grid2[0, 0])\n",
    "        rewards_ax.plot(training_metrics['rewards'], 'b-')\n",
    "        rewards_ax.set_title('Training Rewards', fontsize=14)\n",
    "        rewards_ax.set_xlabel('Episode', fontsize=12)\n",
    "        rewards_ax.set_ylabel('Total Reward', fontsize=12)\n",
    "        rewards_ax.grid(True)\n",
    "        \n",
    "        # Plot losses\n",
    "        losses_ax = plt.subplot(grid2[0, 1])\n",
    "        losses_ax.plot(training_metrics['losses'], 'g-')\n",
    "        losses_ax.set_title('Training Loss', fontsize=14)\n",
    "        losses_ax.set_xlabel('Episode', fontsize=12)\n",
    "        losses_ax.set_ylabel('Loss', fontsize=12)\n",
    "        losses_ax.grid(True)\n",
    "        \n",
    "        # Plot tracking errors\n",
    "        errors_ax = plt.subplot(grid2[1, 0])\n",
    "        errors_ax.plot(training_metrics['tracking_errors'], 'r-')\n",
    "        errors_ax.set_title('Training Tracking Errors', fontsize=14)\n",
    "        errors_ax.set_xlabel('Episode', fontsize=12)\n",
    "        errors_ax.set_ylabel('Mean Tracking Error', fontsize=12)\n",
    "        errors_ax.grid(True)\n",
    "        \n",
    "        # Plot control efforts\n",
    "        efforts_ax = plt.subplot(grid2[1, 1])\n",
    "        efforts_ax.plot(training_metrics['control_efforts'], 'orange')\n",
    "        efforts_ax.set_title('Training Control Efforts', fontsize=14)\n",
    "        efforts_ax.set_xlabel('Episode', fontsize=12)\n",
    "        efforts_ax.set_ylabel('Mean Control Effort', fontsize=12)\n",
    "        efforts_ax.grid(True)\n",
    "    \n",
    "    # Make sure everything fits nicely\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save and display\n",
    "    plt.savefig('controller_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(\"Controller visualization saved as 'controller_visualization.png'\")\n",
    "\n",
    "def main():\n",
    "    print(\"Starting RL Controller implementation...\")\n",
    "    \n",
    "    # Configure torch for faster execution\n",
    "    torch.set_num_threads(4)  # Limit number of threads\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn.benchmark = True  # Optimize CUDA operations\n",
    "    \n",
    "    # Get reference trajectory data\n",
    "    reference_data = get_data()\n",
    "    print(f\"Got reference trajectory with shape: {reference_data.shape}\")\n",
    "    \n",
    "    # Normalize between 0-1\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(reference_data)\n",
    "    \n",
    "    # Setup the environment\n",
    "    window_size = 50\n",
    "    control_discretization = 20  # Number of discrete control actions\n",
    "    \n",
    "    # Create environment with control-oriented reward\n",
    "    env = RLControlEnvironment(\n",
    "        reference_trajectory=normalized_data,\n",
    "        window_size=window_size,\n",
    "        control_discretization=control_discretization,\n",
    "        use_simulation=True,  # Use simulation mode\n",
    "        control_effort_weight=0.1  # Weight for control effort penalty\n",
    "    )\n",
    "    \n",
    "    # Create the agent\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    agent = FastDQNAgent(\n",
    "        state_size=window_size,\n",
    "        action_size=control_discretization,\n",
    "        hidden_size=64,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Train the controller agent\n",
    "    print(f\"Training RL controller on {device}...\")\n",
    "    training_metrics = train_rl_controller(env, agent, episodes=100)\n",
    "    \n",
    "    # Save the trained controller\n",
    "    torch.save({\n",
    "        'q_network': agent.q_network.state_dict(),\n",
    "        'target_network': agent.target_network.state_dict(),\n",
    "        'rewards': training_metrics['rewards'],\n",
    "        'losses': training_metrics['losses'],\n",
    "        'tracking_errors': training_metrics['tracking_errors'],\n",
    "        'control_efforts': training_metrics['control_efforts'],\n",
    "        'scaler': scaler\n",
    "    }, 'rl_controller_model.pth')\n",
    "    \n",
    "    print(\"Training complete! Evaluating controller and creating visualizations...\")\n",
    "    \n",
    "def main():\n",
    "    print(\"Starting RL Controller implementation...\")\n",
    "    \n",
    "    # Configure torch for faster execution\n",
    "    torch.set_num_threads(4)  # Limit number of threads\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn.benchmark = True  # Optimize CUDA operations\n",
    "    \n",
    "    # Get reference trajectory data\n",
    "    reference_data = get_data()\n",
    "    print(f\"Got reference trajectory with shape: {reference_data.shape}\")\n",
    "    \n",
    "    # Normalize between 0-1\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(reference_data)\n",
    "    \n",
    "    # Setup the environment\n",
    "    window_size = 50\n",
    "    control_discretization = 20  # Number of discrete control actions\n",
    "    \n",
    "    # Create environment with control-oriented reward\n",
    "    env = RLControlEnvironment(\n",
    "        reference_trajectory=normalized_data,\n",
    "        window_size=window_size,\n",
    "        control_discretization=control_discretization,\n",
    "        use_simulation=True,  # Use simulation mode\n",
    "        control_effort_weight=0.1  # Weight for control effort penalty\n",
    "    )\n",
    "    \n",
    "    # Create the agent\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    agent = FastDQNAgent(\n",
    "        state_size=window_size,\n",
    "        action_size=control_discretization,\n",
    "        hidden_size=64,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Train the controller agent\n",
    "    print(f\"Training RL controller on {device}...\")\n",
    "    training_metrics = train_rl_controller(env, agent, episodes=100)\n",
    "    \n",
    "    # Save the trained controller\n",
    "    torch.save({\n",
    "        'q_network': agent.q_network.state_dict(),\n",
    "        'target_network': agent.target_network.state_dict(),\n",
    "        'rewards': training_metrics['rewards'],\n",
    "        'losses': training_metrics['losses'],\n",
    "        'tracking_errors': training_metrics['tracking_errors'],\n",
    "        'control_efforts': training_metrics['control_efforts'],\n",
    "        'scaler': scaler\n",
    "    }, 'rl_controller_model.pth')\n",
    "    \n",
    "    print(\"Training complete! Evaluating controller and creating visualizations...\")\n",
    "    \n",
    "    # Evaluate the trained controller\n",
    "    evaluation_results = evaluate_controller(env, agent, scaler)\n",
    "    \n",
    "    # Create visualizations for controller performance\n",
    "    create_controller_visualizations(evaluation_results, training_metrics)\n",
    "    \n",
    "    print(\"RL Controller implementation completed successfully!\")\n",
    "\n",
    "# Run the main function when the script is executed\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea1362b9-1674-4ff5-adcb-46309654572b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Ultra-Fast Reactor Temperature Controller...\n",
      "Using device: cpu\n",
      "Generated reference profile with 2000 points\n",
      "Starting turbo training...\n",
      "Starting turbo training for 50 epochs...\n",
      "Epoch 1/50 - Reward: -28.68, Accuracy: 16.50%, Steps: 200, Time: 2.50s\n",
      "Epoch 2/50 - Reward: -17.98, Accuracy: 25.50%, Steps: 200, Time: 3.48s\n",
      "Epoch 3/50 - Reward: -17.69, Accuracy: 32.00%, Steps: 200, Time: 3.76s\n",
      "Epoch 4/50 - Reward: -16.62, Accuracy: 33.50%, Steps: 200, Time: 3.12s\n",
      "Epoch 5/50 - Reward: -18.16, Accuracy: 29.00%, Steps: 200, Time: 3.85s\n",
      "Epoch 6/50 - Reward: -18.31, Accuracy: 28.00%, Steps: 200, Time: 4.30s\n",
      "Epoch 7/50 - Reward: -17.64, Accuracy: 29.50%, Steps: 200, Time: 3.52s\n",
      "Epoch 8/50 - Reward: -17.27, Accuracy: 32.00%, Steps: 200, Time: 3.46s\n",
      "Epoch 9/50 - Reward: -17.88, Accuracy: 29.50%, Steps: 200, Time: 4.00s\n",
      "Epoch 10/50 - Reward: -18.44, Accuracy: 25.00%, Steps: 200, Time: 3.60s\n",
      "Epoch 11/50 - Reward: -17.62, Accuracy: 26.50%, Steps: 200, Time: 3.08s\n",
      "Epoch 12/50 - Reward: -18.98, Accuracy: 27.50%, Steps: 200, Time: 3.18s\n",
      "Epoch 13/50 - Reward: -17.42, Accuracy: 31.50%, Steps: 200, Time: 3.44s\n",
      "Epoch 14/50 - Reward: -16.75, Accuracy: 33.50%, Steps: 200, Time: 3.41s\n",
      "Epoch 15/50 - Reward: -17.50, Accuracy: 30.00%, Steps: 200, Time: 3.28s\n",
      "Epoch 16/50 - Reward: -17.08, Accuracy: 31.00%, Steps: 200, Time: 3.11s\n",
      "Epoch 17/50 - Reward: -17.67, Accuracy: 29.50%, Steps: 200, Time: 3.11s\n",
      "Epoch 18/50 - Reward: -18.54, Accuracy: 26.00%, Steps: 200, Time: 3.24s\n",
      "Epoch 19/50 - Reward: -17.95, Accuracy: 30.00%, Steps: 200, Time: 4.01s\n",
      "Epoch 20/50 - Reward: -17.79, Accuracy: 29.00%, Steps: 200, Time: 3.20s\n",
      "Epoch 21/50 - Reward: -16.70, Accuracy: 33.50%, Steps: 200, Time: 3.03s\n",
      "Epoch 22/50 - Reward: -18.49, Accuracy: 26.50%, Steps: 200, Time: 3.11s\n",
      "Epoch 23/50 - Reward: -17.94, Accuracy: 27.50%, Steps: 200, Time: 3.08s\n",
      "Epoch 24/50 - Reward: -17.32, Accuracy: 29.00%, Steps: 200, Time: 3.66s\n",
      "Epoch 25/50 - Reward: -17.95, Accuracy: 28.50%, Steps: 200, Time: 3.08s\n",
      "Epoch 26/50 - Reward: -17.76, Accuracy: 29.50%, Steps: 200, Time: 3.08s\n",
      "Epoch 27/50 - Reward: -17.84, Accuracy: 29.00%, Steps: 200, Time: 3.08s\n",
      "Epoch 28/50 - Reward: -18.67, Accuracy: 26.00%, Steps: 200, Time: 3.08s\n",
      "Epoch 29/50 - Reward: -18.96, Accuracy: 24.00%, Steps: 200, Time: 3.62s\n",
      "Epoch 30/50 - Reward: -17.65, Accuracy: 27.50%, Steps: 200, Time: 3.10s\n",
      "Epoch 31/50 - Reward: -17.13, Accuracy: 31.50%, Steps: 200, Time: 3.18s\n",
      "Epoch 32/50 - Reward: -18.78, Accuracy: 26.50%, Steps: 200, Time: 3.11s\n",
      "Epoch 33/50 - Reward: -18.66, Accuracy: 26.50%, Steps: 200, Time: 3.22s\n",
      "Epoch 34/50 - Reward: -17.25, Accuracy: 31.50%, Steps: 200, Time: 4.02s\n",
      "Epoch 35/50 - Reward: -17.00, Accuracy: 29.00%, Steps: 200, Time: 3.78s\n",
      "Epoch 36/50 - Reward: -16.80, Accuracy: 31.00%, Steps: 200, Time: 6.38s\n",
      "Epoch 37/50 - Reward: -19.18, Accuracy: 26.50%, Steps: 200, Time: 6.55s\n",
      "Epoch 38/50 - Reward: -18.16, Accuracy: 27.00%, Steps: 200, Time: 3.86s\n",
      "Epoch 39/50 - Reward: -18.66, Accuracy: 27.00%, Steps: 200, Time: 6.41s\n",
      "Epoch 40/50 - Reward: -19.18, Accuracy: 24.00%, Steps: 200, Time: 6.81s\n",
      "Epoch 41/50 - Reward: -19.36, Accuracy: 26.00%, Steps: 200, Time: 4.31s\n",
      "Epoch 42/50 - Reward: -17.79, Accuracy: 29.00%, Steps: 200, Time: 4.53s\n",
      "Epoch 43/50 - Reward: -16.38, Accuracy: 36.00%, Steps: 200, Time: 4.88s\n",
      "Epoch 44/50 - Reward: -16.72, Accuracy: 31.50%, Steps: 200, Time: 4.81s\n",
      "Epoch 45/50 - Reward: -18.44, Accuracy: 25.50%, Steps: 200, Time: 4.78s\n",
      "Epoch 46/50 - Reward: -17.73, Accuracy: 28.00%, Steps: 200, Time: 4.44s\n",
      "Epoch 47/50 - Reward: -17.06, Accuracy: 31.00%, Steps: 200, Time: 5.44s\n",
      "Epoch 48/50 - Reward: -17.05, Accuracy: 31.00%, Steps: 200, Time: 4.89s\n",
      "Epoch 49/50 - Reward: -17.12, Accuracy: 31.50%, Steps: 200, Time: 6.57s\n",
      "Epoch 50/50 - Reward: -17.21, Accuracy: 30.00%, Steps: 200, Time: 5.22s\n",
      "\n",
      "Training completed in 197.78 seconds\n",
      "Best accuracy: 36.00%\n",
      "Evaluating controller...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ajay\\AppData\\Local\\Temp\\ipykernel_15120\\158427543.py:377: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Final Accuracy: 2.41%\n",
      "RMSE: 0.4999\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reactor Temperature Controller successfully completed!\n",
      "Final accuracy: 2.41%\n",
      "Training time: 197.78 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Fix random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Highly optimized lightweight actor network\n",
    "class FastActor(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hidden_size=32):\n",
    "        super(FastActor, self).__init__()\n",
    "        \n",
    "        # Simple feedforward network - much faster than LSTM\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(state_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, action_size),\n",
    "            nn.Tanh()  # Output in range [-1, 1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, state):\n",
    "        if isinstance(state, np.ndarray):\n",
    "            state = torch.FloatTensor(state)\n",
    "            \n",
    "        return self.net(state)\n",
    "\n",
    "# Lightweight critic network\n",
    "class FastCritic(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hidden_size=32):\n",
    "        super(FastCritic, self).__init__()\n",
    "        \n",
    "        # Input layers for state\n",
    "        self.state_net = nn.Sequential(\n",
    "            nn.Linear(state_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Combined layers for state+action\n",
    "        self.combined_net = nn.Sequential(\n",
    "            nn.Linear(hidden_size + action_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, state, action):\n",
    "        if isinstance(state, np.ndarray):\n",
    "            state = torch.FloatTensor(state)\n",
    "            \n",
    "        if isinstance(action, np.ndarray):\n",
    "            action = torch.FloatTensor(action)\n",
    "            \n",
    "        state_features = self.state_net(state)\n",
    "        combined = torch.cat([state_features, action], dim=1)\n",
    "        return self.combined_net(combined)\n",
    "\n",
    "# Simplified reactor model - faster simulation\n",
    "class FastReactorModel:\n",
    "    def __init__(self, heating_rate=2.0, cooling_rate=1.0, dt=0.1):\n",
    "        self.heating_rate = heating_rate\n",
    "        self.cooling_rate = cooling_rate\n",
    "        self.dt = dt\n",
    "        self.temperature = 25.0\n",
    "    \n",
    "    def reset(self, temperature=25.0):\n",
    "        self.temperature = temperature\n",
    "        return self.temperature\n",
    "    \n",
    "    def step(self, control_power):\n",
    "        # Determine heating or cooling effect\n",
    "        if control_power > 0:\n",
    "            # Heating\n",
    "            effect = control_power * self.heating_rate\n",
    "        else:\n",
    "            # Cooling\n",
    "            effect = control_power * self.cooling_rate\n",
    "            \n",
    "        # Update temperature with minimal computation\n",
    "        self.temperature += effect * self.dt\n",
    "        \n",
    "        # Add small random noise\n",
    "        self.temperature += np.random.normal(0, 0.1)\n",
    "        \n",
    "        # Apply physical bounds\n",
    "        self.temperature = np.clip(self.temperature, 20.0, 120.0)\n",
    "        \n",
    "        return self.temperature\n",
    "\n",
    "# Ultra-fast streamlined environment\n",
    "class FastReactorEnvironment:\n",
    "    def __init__(self, reference_trajectory, window_size=10):\n",
    "        self.reference_trajectory = reference_trajectory\n",
    "        self.window_size = window_size\n",
    "        self.reactor = FastReactorModel()\n",
    "        \n",
    "        # Current position in trajectory\n",
    "        self.current_idx = window_size\n",
    "        self.max_idx = len(reference_trajectory) - 1\n",
    "        \n",
    "        # History of temperatures\n",
    "        self.temperature_history = np.ones(window_size) * 25.0\n",
    "        \n",
    "        # Performance metrics\n",
    "        self.total_error = 0\n",
    "        self.steps = 0\n",
    "        self.accurate_steps = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        self.current_idx = self.window_size\n",
    "        self.reactor.reset(temperature=25.0)\n",
    "        \n",
    "        # Reset history\n",
    "        self.temperature_history = np.ones(self.window_size) * 25.0\n",
    "        \n",
    "        # Reset metrics\n",
    "        self.total_error = 0\n",
    "        self.steps = 0\n",
    "        self.accurate_steps = 0\n",
    "        \n",
    "        # Return normalized state\n",
    "        state = (self.temperature_history - 20.0) / 100.0\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Ensure action is a float\n",
    "        if isinstance(action, np.ndarray):\n",
    "            if action.size == 1:\n",
    "                action = float(action.item())\n",
    "        \n",
    "        # Apply control to reactor\n",
    "        new_temperature = self.reactor.step(action)\n",
    "        \n",
    "        # Get current setpoint\n",
    "        current_setpoint = self.reference_trajectory[self.current_idx][0] * 100 + 20\n",
    "        \n",
    "        # Calculate tracking error\n",
    "        normalized_measured = (new_temperature - 20.0) / 100.0\n",
    "        normalized_setpoint = self.reference_trajectory[self.current_idx][0]\n",
    "        tracking_error = abs(normalized_measured - normalized_setpoint)\n",
    "        \n",
    "        # Simple reward function - ensure it's a scalar float\n",
    "        reward = float(-tracking_error)\n",
    "        \n",
    "        # Update history - more efficient method that doesn't create temporary arrays\n",
    "        self.temperature_history = np.roll(self.temperature_history, -1)\n",
    "        self.temperature_history[-1] = new_temperature\n",
    "        \n",
    "        # Update metrics\n",
    "        self.total_error += float(tracking_error)\n",
    "        self.steps += 1\n",
    "        if tracking_error < 0.05:  # 5% error margin\n",
    "            self.accurate_steps += 1\n",
    "        \n",
    "        # Move to next setpoint\n",
    "        self.current_idx += 1\n",
    "        done = self.current_idx >= self.max_idx\n",
    "        \n",
    "        # Calculate current accuracy\n",
    "        accuracy = float(self.accurate_steps / self.steps if self.steps > 0 else 0)\n",
    "        \n",
    "        # Get new state\n",
    "        if not done:\n",
    "            next_state = (self.temperature_history - 20.0) / 100.0\n",
    "        else:\n",
    "            next_state = np.zeros(self.window_size)\n",
    "            \n",
    "        return next_state, reward, done, {\n",
    "            'tracking_error': float(tracking_error),\n",
    "            'temperature': float(new_temperature),\n",
    "            'setpoint': float(current_setpoint),\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "\n",
    "# Extremely optimized replay buffer using NumPy arrays and vectorized operations\n",
    "class TurboReplayBuffer:\n",
    "    def __init__(self, capacity=10000, state_size=10, action_size=1):\n",
    "        # Pre-allocate memory\n",
    "        self.states = np.zeros((capacity, state_size), dtype=np.float32)\n",
    "        self.actions = np.zeros((capacity, action_size), dtype=np.float32)\n",
    "        self.rewards = np.zeros(capacity, dtype=np.float32)\n",
    "        self.next_states = np.zeros((capacity, state_size), dtype=np.float32)\n",
    "        self.dones = np.zeros(capacity, dtype=np.float32)\n",
    "        \n",
    "        self.capacity = capacity\n",
    "        self.pos = 0\n",
    "        self.size = 0\n",
    "        self.action_size = action_size\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        # Store experience directly\n",
    "        self.states[self.pos] = state\n",
    "        \n",
    "        # Handle scalar vs vector actions\n",
    "        if isinstance(action, (int, float)):\n",
    "            self.actions[self.pos, 0] = float(action)\n",
    "        elif isinstance(action, np.ndarray):\n",
    "            if action.size == 1:\n",
    "                self.actions[self.pos, 0] = float(action.item())\n",
    "            else:\n",
    "                self.actions[self.pos] = action\n",
    "        else:\n",
    "            self.actions[self.pos] = action\n",
    "            \n",
    "        # Ensure reward is a simple float, not array\n",
    "        if isinstance(reward, np.ndarray):\n",
    "            self.rewards[self.pos] = float(reward.item())\n",
    "        else:\n",
    "            self.rewards[self.pos] = float(reward)\n",
    "            \n",
    "        self.next_states[self.pos] = next_state\n",
    "        self.dones[self.pos] = float(done)\n",
    "        \n",
    "        # Update position and size\n",
    "        self.pos = (self.pos + 1) % self.capacity\n",
    "        self.size = min(self.size + 1, self.capacity)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        # Vectorized sampling for speed\n",
    "        indices = np.random.randint(0, self.size, size=batch_size)\n",
    "        \n",
    "        return (\n",
    "            torch.FloatTensor(self.states[indices]),\n",
    "            torch.FloatTensor(self.actions[indices]),\n",
    "            torch.FloatTensor(self.rewards[indices]),\n",
    "            torch.FloatTensor(self.next_states[indices]),\n",
    "            torch.FloatTensor(self.dones[indices])\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "# Ultra-fast DDPG agent with optimized hyperparameters\n",
    "class TurboDDPGAgent:\n",
    "    def __init__(self, state_size, action_size, hidden_size=32, device='cpu'):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.device = device\n",
    "        self.gamma = 0.99\n",
    "        self.tau = 0.01\n",
    "        self.batch_size = 64  # Smaller batch for speed\n",
    "        self.exploration_noise = 0.3\n",
    "        \n",
    "        # Networks - smaller and faster\n",
    "        self.actor = FastActor(state_size, action_size, hidden_size).to(device)\n",
    "        self.actor_target = FastActor(state_size, action_size, hidden_size).to(device)\n",
    "        self.actor_target.load_state_dict(self.actor.state_dict())\n",
    "        \n",
    "        self.critic = FastCritic(state_size, action_size, hidden_size).to(device)\n",
    "        self.critic_target = FastCritic(state_size, action_size, hidden_size).to(device)\n",
    "        self.critic_target.load_state_dict(self.critic.state_dict())\n",
    "        \n",
    "        # Fast optimizers with higher learning rates\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=0.001)\n",
    "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=0.002)\n",
    "        \n",
    "        # Memory - smaller capacity for speed\n",
    "        self.memory = TurboReplayBuffer(capacity=5000, state_size=state_size, action_size=action_size)\n",
    "        \n",
    "        # Use autocast for mixed precision if on CUDA (much faster)\n",
    "        self.use_autocast = device.type == 'cuda'\n",
    "    \n",
    "    def select_action(self, state, add_noise=True):\n",
    "        with torch.no_grad():\n",
    "            if isinstance(state, np.ndarray):\n",
    "                state = torch.FloatTensor(state).to(self.device)\n",
    "            \n",
    "            # Get action and ensure it's a scalar if action_size is 1\n",
    "            action = self.actor(state).cpu().numpy()\n",
    "            \n",
    "            if self.action_size == 1 and action.size == 1:\n",
    "                action = float(action.item())  # Convert single-element array to scalar\n",
    "                \n",
    "                if add_noise:\n",
    "                    action += float(np.random.normal(0, self.exploration_noise))\n",
    "                    action = np.clip(action, -1.0, 1.0)\n",
    "            else:\n",
    "                if add_noise:\n",
    "                    action += np.random.normal(0, self.exploration_noise, size=self.action_size)\n",
    "                    action = np.clip(action, -1.0, 1.0)\n",
    "                \n",
    "            return action\n",
    "    \n",
    "    def train_step(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return 0, 0\n",
    "        \n",
    "        # Sample a batch\n",
    "        states, actions, rewards, next_states, dones = self.memory.sample(self.batch_size)\n",
    "        \n",
    "        # Move to device\n",
    "        states = states.to(self.device)\n",
    "        actions = actions.to(self.device)\n",
    "        rewards = rewards.to(self.device)\n",
    "        next_states = next_states.to(self.device)\n",
    "        dones = dones.to(self.device)\n",
    "        \n",
    "        # Training with autocast if available\n",
    "        if self.use_autocast:\n",
    "            with torch.autocast(device_type='cuda'):\n",
    "                # Compute target actions and Q values\n",
    "                with torch.no_grad():\n",
    "                    next_actions = self.actor_target(next_states)\n",
    "                    next_q = self.critic_target(next_states, next_actions).squeeze()\n",
    "                    target_q = rewards + (1 - dones) * self.gamma * next_q\n",
    "                \n",
    "                # Compute current Q\n",
    "                current_q = self.critic(states, actions).squeeze()\n",
    "                \n",
    "                # Compute losses\n",
    "                critic_loss = F.mse_loss(current_q, target_q)\n",
    "                \n",
    "                # Update critic\n",
    "                self.critic_optimizer.zero_grad()\n",
    "                critic_loss.backward()\n",
    "                self.critic_optimizer.step()\n",
    "                \n",
    "                # Update actor\n",
    "                actions_pred = self.actor(states)\n",
    "                actor_loss = -self.critic(states, actions_pred).mean()\n",
    "                \n",
    "                self.actor_optimizer.zero_grad()\n",
    "                actor_loss.backward()\n",
    "                self.actor_optimizer.step()\n",
    "        else:\n",
    "            # Standard training path for CPU\n",
    "            with torch.no_grad():\n",
    "                next_actions = self.actor_target(next_states)\n",
    "                next_q = self.critic_target(next_states, next_actions).squeeze()\n",
    "                target_q = rewards + (1 - dones) * self.gamma * next_q\n",
    "            \n",
    "            # Compute current Q\n",
    "            current_q = self.critic(states, actions).squeeze()\n",
    "            \n",
    "            # Compute critic loss and update\n",
    "            critic_loss = F.mse_loss(current_q, target_q)\n",
    "            self.critic_optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            self.critic_optimizer.step()\n",
    "            \n",
    "            # Update actor\n",
    "            actions_pred = self.actor(states)\n",
    "            actor_loss = -self.critic(states, actions_pred).mean()\n",
    "            \n",
    "            self.actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            self.actor_optimizer.step()\n",
    "        \n",
    "        # Soft update target networks - vectorized for speed\n",
    "        self._soft_update()\n",
    "        \n",
    "        return critic_loss.item(), actor_loss.item()\n",
    "    \n",
    "    def _soft_update(self):\n",
    "        # Faster vectorized soft update\n",
    "        for target_param, param in zip(self.actor_target.parameters(), self.actor.parameters()):\n",
    "            target_param.data.copy_(target_param.data * (1.0 - self.tau) + param.data * self.tau)\n",
    "            \n",
    "        for target_param, param in zip(self.critic_target.parameters(), self.critic.parameters()):\n",
    "            target_param.data.copy_(target_param.data * (1.0 - self.tau) + param.data * self.tau)\n",
    "            \n",
    "    def save(self, path):\n",
    "        torch.save({\n",
    "            'actor': self.actor.state_dict(),\n",
    "            'critic': self.critic.state_dict(),\n",
    "        }, path)\n",
    "    \n",
    "    def load(self, path):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.actor.load_state_dict(checkpoint['actor'])\n",
    "        self.actor_target.load_state_dict(checkpoint['actor'])\n",
    "        self.critic.load_state_dict(checkpoint['critic'])\n",
    "        self.critic_target.load_state_dict(checkpoint['critic'])\n",
    "\n",
    "# Generate simplified temperature profile\n",
    "def generate_simple_profile(length=2000):\n",
    "    data = np.zeros((length, 1))\n",
    "    \n",
    "    # Starting temperature\n",
    "    data[:200] = 0.25  # 45°C\n",
    "    \n",
    "    # Ramp up\n",
    "    for i in range(200, 600):\n",
    "        progress = (i - 200) / 400\n",
    "        data[i] = 0.25 + progress * 0.45  # 45°C to 70°C\n",
    "    \n",
    "    # Hold\n",
    "    data[600:1200] = 0.7  # 70°C\n",
    "    \n",
    "    # Ramp down\n",
    "    for i in range(1200, 1800):\n",
    "        progress = (i - 1200) / 600\n",
    "        data[i] = 0.7 - progress * 0.6  # 70°C to 30°C\n",
    "    \n",
    "    # Final temperature\n",
    "    data[1800:] = 0.1  # 30°C\n",
    "    \n",
    "    return data.astype(np.float32)\n",
    "\n",
    "# Ultra-fast training function\n",
    "def turbo_train(env, agent, epochs=10, steps_per_epoch=200):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training metrics\n",
    "    rewards_history = []\n",
    "    accuracy_history = []\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    print(f\"Starting turbo training for {epochs} epochs...\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        state = env.reset()\n",
    "        epoch_reward = 0.0  # Ensure this is a float, not an array\n",
    "        epoch_steps = 0\n",
    "        last_accuracy = 0.0\n",
    "        \n",
    "        # Run for fixed number of steps per epoch\n",
    "        for step in range(steps_per_epoch):\n",
    "            # Select action\n",
    "            action = agent.select_action(state, add_noise=True)\n",
    "            \n",
    "            # Take step in environment\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            # Store in replay buffer\n",
    "            agent.memory.add(state, action, reward, next_state, done)\n",
    "            \n",
    "            # Update state and metrics\n",
    "            state = next_state\n",
    "            if isinstance(reward, np.ndarray):\n",
    "                epoch_reward += float(reward.item())\n",
    "            else:\n",
    "                epoch_reward += float(reward)\n",
    "            \n",
    "            epoch_steps += 1\n",
    "            last_accuracy = info['accuracy']  # Save latest accuracy\n",
    "            \n",
    "            # Train multiple times per step for faster convergence\n",
    "            for _ in range(4):  # Multiple updates per step\n",
    "                agent.train_step()\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        # Record metrics - ensure we're using scalars\n",
    "        accuracy = float(last_accuracy)\n",
    "        rewards_history.append(float(epoch_reward))\n",
    "        accuracy_history.append(accuracy)\n",
    "        \n",
    "        # Save best model\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            agent.save('best_reactor_model.pt')\n",
    "        \n",
    "        # Print progress with confirmed scalar values\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Reward: {float(epoch_reward):.2f}, \"\n",
    "              f\"Accuracy: {float(accuracy*100):.2f}%, Steps: {epoch_steps}, \"\n",
    "              f\"Time: {epoch_time:.2f}s\")\n",
    "        \n",
    "        # Early stopping if accuracy is good enough\n",
    "        if accuracy > 0.95:\n",
    "            print(\"Target accuracy reached! Stopping training.\")\n",
    "            break\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {total_time:.2f} seconds\")\n",
    "    print(f\"Best accuracy: {best_accuracy*100:.2f}%\")\n",
    "    \n",
    "    # Load best model\n",
    "    agent.load('best_reactor_model.pt')\n",
    "    \n",
    "    return {\n",
    "        'rewards': rewards_history,\n",
    "        'accuracy_history': accuracy_history,\n",
    "        'best_accuracy': best_accuracy,\n",
    "        'training_time': total_time\n",
    "    }\n",
    "\n",
    "# Fast evaluation\n",
    "def evaluate(env, agent):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    # Arrays to store results\n",
    "    temperatures = []\n",
    "    setpoints = []\n",
    "    actions = []\n",
    "    accuracy_values = []\n",
    "    \n",
    "    # Evaluate without exploration noise\n",
    "    while not done:\n",
    "        action = agent.select_action(state, add_noise=False)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        # Record results\n",
    "        temperatures.append(info['temperature'])\n",
    "        setpoints.append(info['setpoint'])\n",
    "        actions.append(action[0] if isinstance(action, np.ndarray) else action)\n",
    "        accuracy_values.append(info['accuracy'])\n",
    "        \n",
    "        state = next_state\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    final_accuracy = accuracy_values[-1]\n",
    "    temperatures = np.array(temperatures)\n",
    "    setpoints = np.array(setpoints)\n",
    "    \n",
    "    # Calculate error metrics\n",
    "    errors = np.abs(temperatures - setpoints)\n",
    "    rmse = np.sqrt(np.mean(np.square(errors / 100)))  # Normalized RMSE\n",
    "    \n",
    "    print(f\"Evaluation Results:\")\n",
    "    print(f\"Final Accuracy: {final_accuracy*100:.2f}%\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'temperatures': temperatures,\n",
    "        'setpoints': setpoints,\n",
    "        'actions': actions,\n",
    "        'accuracy': final_accuracy,\n",
    "        'rmse': rmse\n",
    "    }\n",
    "\n",
    "# Visualization function\n",
    "def plot_results(eval_results, training_metrics=None):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot temperature control\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(eval_results['setpoints'], 'r--', label='Setpoint')\n",
    "    plt.plot(eval_results['temperatures'], 'b-', label='Actual')\n",
    "    plt.title(f'Reactor Temperature Control (Accuracy: {eval_results[\"accuracy\"]*100:.2f}%)')\n",
    "    plt.ylabel('Temperature (°C)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot control actions\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(eval_results['actions'], 'g-')\n",
    "    plt.title('Control Actions')\n",
    "    plt.ylabel('Action [-1, 1]')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot training metrics if available\n",
    "    if training_metrics:\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.plot(np.array(training_metrics['accuracy_history'])*100, 'b-')\n",
    "        plt.title('Training Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('reactor_control_results.png', dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    print(\"Starting Ultra-Fast Reactor Temperature Controller...\")\n",
    "    \n",
    "    # Use CUDA if available for maximum speed\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Generate simplified profile for faster training\n",
    "    reference_data = generate_simple_profile()\n",
    "    print(f\"Generated reference profile with {len(reference_data)} points\")\n",
    "    \n",
    "    # Create fast environment\n",
    "    window_size = 10  # Smaller window for speed\n",
    "    env = FastReactorEnvironment(\n",
    "        reference_trajectory=reference_data,\n",
    "        window_size=window_size\n",
    "    )\n",
    "    \n",
    "    # Create agent\n",
    "    agent = TurboDDPGAgent(\n",
    "        state_size=window_size,\n",
    "        action_size=1,\n",
    "        hidden_size=32,  # Smaller network\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Train using turbo mode\n",
    "    print(\"Starting turbo training...\")\n",
    "    training_metrics = turbo_train(\n",
    "        env=env,\n",
    "        agent=agent,\n",
    "        epochs=50,  # More epochs but faster per epoch\n",
    "        steps_per_epoch=200  # Limit steps per epoch\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"Evaluating controller...\")\n",
    "    eval_results = evaluate(env, agent)\n",
    "    \n",
    "    # Plot results\n",
    "    plot_results(eval_results, training_metrics)\n",
    "    \n",
    "    print(\"\\nReactor Temperature Controller successfully completed!\")\n",
    "    print(f\"Final accuracy: {eval_results['accuracy']*100:.2f}%\")\n",
    "    print(f\"Training time: {training_metrics['training_time']:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ceea0-fb95-4280-a618-b66b5d3e2006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting High-Accuracy Reactor Temperature Controller...\n",
      "Using device: cpu\n",
      "Generating complex reactor temperature profile...\n",
      "Generated reference trajectory with 5000 points\n",
      "Starting precision training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 5005/50000 [01:06<34:28, 21.75it/s, episode=11, reward=0.45, acc=1.20%, high_acc=0.40%, noise=0.020]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model at step 5000:\n",
      "Standard Accuracy: 1.20%\n",
      "High Accuracy: 0.40%\n",
      "RMSE: 0.5694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 9228/50000 [02:11<08:43, 77.85it/s, episode=19, reward=-252.19, acc=1.20%, high_acc=0.40%, noise=0.020]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Fix random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Advanced network architecture optimized for accuracy\n",
    "class EnhancedActor(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hidden_size=64):\n",
    "        super(EnhancedActor, self).__init__()\n",
    "        \n",
    "        # Initial state processing with residual connections\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(state_size, hidden_size),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Residual block 1\n",
    "        self.res1 = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LayerNorm(hidden_size)\n",
    "        )\n",
    "        \n",
    "        # Residual block 2\n",
    "        self.res2 = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LayerNorm(hidden_size)\n",
    "        )\n",
    "        \n",
    "        # Output layer with normalized activation\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size, action_size),\n",
    "            nn.Tanh()  # Output in range [-1, 1]\n",
    "        )\n",
    "        \n",
    "        # Initialize weights for better convergence\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize network weights with specific strategy for better convergence\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                # Kaiming initialization for ReLU networks\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                # Small non-zero bias for stability\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.01)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        if isinstance(state, np.ndarray):\n",
    "            state = torch.FloatTensor(state)\n",
    "            \n",
    "        # Initial layer\n",
    "        x = self.input_layer(state)\n",
    "        \n",
    "        # Residual block 1 with skip connection\n",
    "        residual = x\n",
    "        x = self.res1(x) + residual\n",
    "        \n",
    "        # Residual block 2 with skip connection\n",
    "        residual = x\n",
    "        x = self.res2(x) + residual\n",
    "        \n",
    "        # Output action\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Advanced critic network with double Q-learning concept\n",
    "class EnhancedCritic(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hidden_size=64):\n",
    "        super(EnhancedCritic, self).__init__()\n",
    "        \n",
    "        # State processing branch\n",
    "        self.state_path = nn.Sequential(\n",
    "            nn.Linear(state_size, hidden_size),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Combined processing (state+action)\n",
    "        self.combined_path = nn.Sequential(\n",
    "            nn.Linear(hidden_size + action_size, hidden_size),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Dual Q-value outputs for Double Q-Learning\n",
    "        self.q1_output = nn.Linear(hidden_size, 1)\n",
    "        self.q2_output = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        # Initialize with same strategy as actor\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.01)\n",
    "    \n",
    "    def forward(self, state, action):\n",
    "        if isinstance(state, np.ndarray):\n",
    "            state = torch.FloatTensor(state)\n",
    "            \n",
    "        if isinstance(action, np.ndarray):\n",
    "            action = torch.FloatTensor(action)\n",
    "            \n",
    "        # Process state\n",
    "        state_features = self.state_path(state)\n",
    "        \n",
    "        # Combine state and action\n",
    "        combined = torch.cat([state_features, action], dim=1)\n",
    "        features = self.combined_path(combined)\n",
    "        \n",
    "        # Dual Q-values\n",
    "        q1 = self.q1_output(features)\n",
    "        q2 = self.q2_output(features)\n",
    "        \n",
    "        return q1, q2\n",
    "    \n",
    "    def q1(self, state, action):\n",
    "        \"\"\"For policy optimization we only need one Q-value\"\"\"\n",
    "        q1, _ = self.forward(state, action)\n",
    "        return q1\n",
    "\n",
    "# Precision-optimized replay buffer\n",
    "class PrecisionReplayBuffer:\n",
    "    def __init__(self, capacity=100000, state_size=20, action_size=1):\n",
    "        self.capacity = capacity\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        # Pre-allocate memory\n",
    "        self.states = np.zeros((capacity, state_size), dtype=np.float32)\n",
    "        self.actions = np.zeros((capacity, action_size), dtype=np.float32)\n",
    "        self.rewards = np.zeros(capacity, dtype=np.float32)\n",
    "        self.next_states = np.zeros((capacity, state_size), dtype=np.float32)\n",
    "        self.dones = np.zeros(capacity, dtype=np.float32)\n",
    "        \n",
    "        # Priority metrics for prioritized experience replay\n",
    "        self.priorities = np.ones(capacity, dtype=np.float32)\n",
    "        \n",
    "        self.pos = 0\n",
    "        self.size = 0\n",
    "        \n",
    "    def add(self, state, action, reward, next_state, done, priority=None):\n",
    "        # Process scalars to float and arrays appropriately \n",
    "        self.states[self.pos] = state\n",
    "        \n",
    "        # Handle different action formats\n",
    "        if isinstance(action, (int, float)):\n",
    "            self.actions[self.pos, 0] = float(action)\n",
    "        elif isinstance(action, np.ndarray):\n",
    "            if action.size == 1:\n",
    "                self.actions[self.pos, 0] = float(action.item())\n",
    "            else:\n",
    "                self.actions[self.pos] = action\n",
    "        else:\n",
    "            self.actions[self.pos] = action\n",
    "            \n",
    "        # Handle reward\n",
    "        if isinstance(reward, np.ndarray):\n",
    "            self.rewards[self.pos] = float(reward.item())\n",
    "        else:\n",
    "            self.rewards[self.pos] = float(reward)\n",
    "            \n",
    "        self.next_states[self.pos] = next_state\n",
    "        self.dones[self.pos] = float(done)\n",
    "        \n",
    "        # Set priority (for prioritized replay)\n",
    "        if priority is not None:\n",
    "            self.priorities[self.pos] = float(priority)\n",
    "        else:\n",
    "            # Default to max priority for new experiences\n",
    "            self.priorities[self.pos] = float(np.max(self.priorities[:self.size])) if self.size > 0 else 1.0\n",
    "        \n",
    "        # Update position and size\n",
    "        self.pos = (self.pos + 1) % self.capacity\n",
    "        self.size = min(self.size + 1, self.capacity)\n",
    "    \n",
    "    def sample(self, batch_size, prioritized=True):\n",
    "        if prioritized and self.size > 1:\n",
    "            # Prioritized sampling with temperature-adjusted probabilities\n",
    "            probs = self.priorities[:self.size] ** 0.6  # Alpha parameter\n",
    "            probs = probs / np.sum(probs)\n",
    "            \n",
    "            # Sample with replacement according to priorities\n",
    "            indices = np.random.choice(self.size, batch_size, replace=True, p=probs)\n",
    "            \n",
    "            # Calculate importance sampling weights\n",
    "            weights = (self.size * probs[indices]) ** -0.4  # Beta parameter\n",
    "            weights = weights / np.max(weights)\n",
    "            weights_tensor = torch.FloatTensor(weights).reshape(-1, 1)\n",
    "        else:\n",
    "            # Uniform sampling\n",
    "            indices = np.random.choice(self.size, batch_size, replace=True)\n",
    "            weights_tensor = torch.ones((batch_size, 1))\n",
    "        \n",
    "        return (\n",
    "            torch.FloatTensor(self.states[indices]),\n",
    "            torch.FloatTensor(self.actions[indices]),\n",
    "            torch.FloatTensor(self.rewards[indices]).reshape(-1, 1),\n",
    "            torch.FloatTensor(self.next_states[indices]),\n",
    "            torch.FloatTensor(self.dones[indices]).reshape(-1, 1),\n",
    "            indices,\n",
    "            weights_tensor\n",
    "        )\n",
    "    \n",
    "    def update_priorities(self, indices, priorities):\n",
    "        \"\"\"Update priorities for prioritized replay\"\"\"\n",
    "        for idx, priority in zip(indices, priorities):\n",
    "            self.priorities[idx] = float(priority)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "# Improved reactor model with better dynamics\n",
    "class PrecisionReactorModel:\n",
    "    def __init__(self, heating_rate=1.5, cooling_rate=0.8, ambient_temp=25.0, \n",
    "                 inertia=2.0, noise_level=0.03):\n",
    "        self.heating_rate = heating_rate\n",
    "        self.cooling_rate = cooling_rate\n",
    "        self.ambient_temp = ambient_temp\n",
    "        self.inertia = inertia\n",
    "        self.noise_level = noise_level\n",
    "        \n",
    "        # State variables\n",
    "        self.temperature = ambient_temp\n",
    "        self.heat_momentum = 0.0  # Temperature change momentum\n",
    "        \n",
    "        # Previous control values for more realistic dynamics\n",
    "        self.prev_controls = [0.0] * 5  # Last 5 control values\n",
    "        \n",
    "    def reset(self, temperature=None):\n",
    "        \"\"\"Reset reactor to initial temperature\"\"\"\n",
    "        if temperature is None:\n",
    "            temperature = self.ambient_temp\n",
    "            \n",
    "        self.temperature = temperature\n",
    "        self.heat_momentum = 0.0\n",
    "        self.prev_controls = [0.0] * 5\n",
    "        \n",
    "        return self.temperature\n",
    "    \n",
    "    def step(self, control_power, dt=0.1):\n",
    "        \"\"\"Apply control action and update temperature with realistic dynamics\"\"\"\n",
    "        # Update control history\n",
    "        self.prev_controls.pop(0)\n",
    "        self.prev_controls.append(float(control_power))\n",
    "        \n",
    "        # Calculate weighted control effect (recent controls have more impact)\n",
    "        weights = [0.1, 0.15, 0.2, 0.25, 0.3]  # More weight to recent controls\n",
    "        weighted_control = sum(w * c for w, c in zip(weights, self.prev_controls))\n",
    "        \n",
    "        # Determine heating or cooling effect with non-linear response\n",
    "        if weighted_control > 0:\n",
    "            # Heating with diminishing returns at higher temperatures\n",
    "            temp_factor = max(0, 1.0 - (self.temperature - self.ambient_temp) / 100.0)\n",
    "            power_effect = weighted_control * self.heating_rate * temp_factor\n",
    "        else:\n",
    "            # Cooling with increased effect at higher temperatures\n",
    "            temp_factor = 1.0 + max(0, (self.temperature - self.ambient_temp) / 100.0)\n",
    "            power_effect = weighted_control * self.cooling_rate * temp_factor\n",
    "            \n",
    "        # Natural cooling to ambient (more pronounced at higher temperatures)\n",
    "        natural_cooling = (self.ambient_temp - self.temperature) * 0.05\n",
    "        \n",
    "        # Apply thermal inertia (weighted combination of new and momentum)\n",
    "        raw_change = (power_effect + natural_cooling) / self.inertia\n",
    "        self.heat_momentum = 0.7 * self.heat_momentum + 0.3 * raw_change\n",
    "        \n",
    "        # Update temperature with momentum and noise\n",
    "        self.temperature += self.heat_momentum * dt\n",
    "        self.temperature += np.random.normal(0, self.noise_level)\n",
    "        \n",
    "        # Ensure physically reasonable bounds\n",
    "        self.temperature = np.clip(self.temperature, 20.0, 150.0)\n",
    "        \n",
    "        return self.temperature\n",
    "\n",
    "# High-precision control environment\n",
    "class PrecisionControlEnvironment:\n",
    "    def __init__(self, reference_trajectory, window_size=20, dt=0.1,\n",
    "                history_overlap=0.5, reward_shaping=True):\n",
    "        \"\"\"Enhanced control environment for higher accuracy\n",
    "        \n",
    "        Args:\n",
    "            reference_trajectory: Target temperature profile\n",
    "            window_size: Size of state window (recent temperatures)\n",
    "            dt: Time step size\n",
    "            history_overlap: Percentage of history to keep between steps (0-1)\n",
    "            reward_shaping: Whether to use shaped rewards for better learning\n",
    "        \"\"\"\n",
    "        self.reference_trajectory = reference_trajectory\n",
    "        self.window_size = window_size\n",
    "        self.dt = dt\n",
    "        self.history_overlap = history_overlap\n",
    "        self.reward_shaping = reward_shaping\n",
    "        \n",
    "        # Calculate how many steps to keep in history\n",
    "        self.history_keep = int(window_size * history_overlap)\n",
    "        self.history_advance = window_size - self.history_keep\n",
    "        \n",
    "        # Create a high-precision reactor model\n",
    "        self.reactor = PrecisionReactorModel()\n",
    "        \n",
    "        # Current position in reference trajectory\n",
    "        self.current_idx = window_size\n",
    "        self.max_idx = len(reference_trajectory) - 1\n",
    "        \n",
    "        # History of temperatures, errors and controls\n",
    "        self.temperature_history = np.ones(window_size) * 25.0\n",
    "        self.error_history = np.zeros(window_size)\n",
    "        self.control_history = np.zeros(window_size)\n",
    "        self.setpoint_history = np.zeros(window_size)\n",
    "        \n",
    "        # Performance metrics\n",
    "        self.total_error = 0.0\n",
    "        self.steps = 0\n",
    "        self.accurate_steps = 0\n",
    "        self.high_accuracy_steps = 0  # Very high accuracy (< 1%)\n",
    "        \n",
    "        # For reward calculation\n",
    "        self.prev_error = 0.0\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Reset environment to initial conditions\"\"\"\n",
    "        self.current_idx = self.window_size\n",
    "        \n",
    "        # Get initial setpoint\n",
    "        initial_setpoint = self.reference_trajectory[0][0] * 100 + 20\n",
    "        self.reactor.reset(temperature=initial_setpoint)\n",
    "        \n",
    "        # Reset history buffers\n",
    "        self.temperature_history = np.ones(self.window_size) * initial_setpoint\n",
    "        self.error_history = np.zeros(self.window_size)\n",
    "        self.control_history = np.zeros(self.window_size)\n",
    "        self.setpoint_history = np.ones(self.window_size) * initial_setpoint\n",
    "        \n",
    "        # Reset metrics\n",
    "        self.total_error = 0.0\n",
    "        self.steps = 0\n",
    "        self.accurate_steps = 0\n",
    "        self.high_accuracy_steps = 0\n",
    "        self.prev_error = 0.0\n",
    "        \n",
    "        # Initial state contains normalized temperature history, setpoint history and error history\n",
    "        state = self._get_normalized_state()\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def _get_normalized_state(self):\n",
    "        \"\"\"Construct the state vector with normalized values\"\"\"\n",
    "        # Normalize temperatures to [0, 1] range\n",
    "        norm_temps = (self.temperature_history - 20.0) / 100.0\n",
    "        \n",
    "        # Normalize setpoints to same range\n",
    "        norm_setpoints = (self.setpoint_history - 20.0) / 100.0\n",
    "        \n",
    "        # Normalized errors are already in good range (-1 to 1)\n",
    "        # Control history is already in [-1, 1] range\n",
    "        \n",
    "        # Combine all information\n",
    "        state = np.concatenate([\n",
    "            norm_temps,  # Temperature history\n",
    "            norm_setpoints,  # Future setpoints for feedforward control\n",
    "            self.error_history,  # Error history for derivative action\n",
    "            self.control_history  # Control history for smoothing\n",
    "        ])\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Take a control action and advance environment\"\"\"\n",
    "        # Ensure action is a float\n",
    "        if isinstance(action, np.ndarray):\n",
    "            if action.size == 1:\n",
    "                action = float(action.item())\n",
    "        \n",
    "        # Apply control to reactor\n",
    "        new_temperature = self.reactor.step(action, dt=self.dt)\n",
    "        \n",
    "        # Look ahead to get multiple setpoints for feedforward information\n",
    "        setpoints = []\n",
    "        for i in range(self.window_size):\n",
    "            idx = min(self.current_idx + i, self.max_idx)\n",
    "            # Convert normalized setpoint to actual temperature\n",
    "            setpoint = self.reference_trajectory[idx][0] * 100 + 20\n",
    "            setpoints.append(setpoint)\n",
    "        \n",
    "        # Current setpoint (target value)\n",
    "        current_setpoint = setpoints[0]\n",
    "        \n",
    "        # Calculate tracking error\n",
    "        current_error = (new_temperature - current_setpoint) / 100.0  # Normalized error\n",
    "        \n",
    "        # Calculate reward components\n",
    "        if self.reward_shaping:\n",
    "            # 1. Error magnitude (primary component)\n",
    "            error_reward = -abs(current_error)\n",
    "            \n",
    "            # 2. Error improvement (derivative component)\n",
    "            error_diff = abs(current_error) - abs(self.prev_error)\n",
    "            improvement_reward = -error_diff * 2.0  # Higher weight for improvement\n",
    "            \n",
    "            # 3. Control smoothness\n",
    "            if len(self.control_history) > 0:\n",
    "                action_change = abs(action - self.control_history[-1])\n",
    "                smoothness_reward = -action_change * 0.3\n",
    "            else:\n",
    "                smoothness_reward = 0.0\n",
    "            \n",
    "            # 4. Staying within tight bounds (bonus)\n",
    "            accuracy_bonus = 0.0\n",
    "            if abs(current_error) < 0.02:  # Within 2% error\n",
    "                accuracy_bonus = 0.5\n",
    "            elif abs(current_error) < 0.05:  # Within 5% error\n",
    "                accuracy_bonus = 0.2\n",
    "                \n",
    "            # Combined reward\n",
    "            reward = (\n",
    "                error_reward * 1.0 +      # Base error term\n",
    "                improvement_reward * 0.7 + # Improvement term\n",
    "                smoothness_reward * 0.3 +  # Smoothness term\n",
    "                accuracy_bonus             # Accuracy bonus\n",
    "            )\n",
    "        else:\n",
    "            # Simple reward based on error magnitude\n",
    "            reward = -abs(current_error)\n",
    "        \n",
    "        # Remember error for next step's derivative calculation\n",
    "        self.prev_error = current_error\n",
    "        \n",
    "        # Update history buffers with overlap strategy\n",
    "        # This allows controlling how much history we retain vs. advance\n",
    "        # More advanced: shift by history_advance instead of just 1 step\n",
    "        if self.history_advance > 1:\n",
    "            # Advanced multiple steps\n",
    "            new_temps = [self.reactor.step(action, dt=self.dt) for _ in range(self.history_advance-1)]\n",
    "            new_temps = [new_temperature] + new_temps\n",
    "            \n",
    "            # Keep some history and add new values\n",
    "            self.temperature_history = np.concatenate([\n",
    "                self.temperature_history[-self.history_keep:],\n",
    "                np.array(new_temps)\n",
    "            ])\n",
    "            \n",
    "            # Update other histories\n",
    "            self.error_history = np.concatenate([\n",
    "                self.error_history[-self.history_keep:],\n",
    "                np.zeros(self.history_advance)\n",
    "            ])\n",
    "            self.error_history[-1] = current_error\n",
    "            \n",
    "            self.control_history = np.concatenate([\n",
    "                self.control_history[-self.history_keep:],\n",
    "                np.zeros(self.history_advance)\n",
    "            ])\n",
    "            self.control_history[-1] = action\n",
    "            \n",
    "            self.setpoint_history = np.array(setpoints)\n",
    "            \n",
    "            # Advance index more\n",
    "            self.current_idx += self.history_advance\n",
    "        else:\n",
    "            # Simple version: advance by 1 step\n",
    "            # Use efficient roll operation\n",
    "            self.temperature_history = np.roll(self.temperature_history, -1)\n",
    "            self.temperature_history[-1] = new_temperature\n",
    "            \n",
    "            self.error_history = np.roll(self.error_history, -1)\n",
    "            self.error_history[-1] = current_error\n",
    "            \n",
    "            self.control_history = np.roll(self.control_history, -1)\n",
    "            self.control_history[-1] = action\n",
    "            \n",
    "            self.setpoint_history = np.array(setpoints)\n",
    "            \n",
    "            # Advance by one step\n",
    "            self.current_idx += 1\n",
    "        \n",
    "        # Update metrics\n",
    "        self.total_error += abs(current_error)\n",
    "        self.steps += 1\n",
    "        if abs(current_error) < 0.05:  # Within 5% error\n",
    "            self.accurate_steps += 1\n",
    "        if abs(current_error) < 0.01:  # Within 1% error\n",
    "            self.high_accuracy_steps += 1\n",
    "        \n",
    "        # Check if done\n",
    "        done = self.current_idx >= self.max_idx\n",
    "        \n",
    "        # Calculate accuracies\n",
    "        std_accuracy = float(self.accurate_steps / self.steps if self.steps > 0 else 0)\n",
    "        high_accuracy = float(self.high_accuracy_steps / self.steps if self.steps > 0 else 0)\n",
    "        \n",
    "        # Get new state\n",
    "        if not done:\n",
    "            next_state = self._get_normalized_state()\n",
    "        else:\n",
    "            next_state = np.zeros(self.window_size * 4)  # 4 history components in state\n",
    "            \n",
    "        # Calculate tracking accuracy percentage for display\n",
    "        tracking_accuracy = max(0, 100 * (1.0 - abs(current_error)))\n",
    "            \n",
    "        return next_state, float(reward), done, {\n",
    "            'tracking_error': float(current_error),\n",
    "            'abs_error': float(abs(current_error)),\n",
    "            'temperature': float(new_temperature),\n",
    "            'setpoint': float(current_setpoint),\n",
    "            'accuracy': std_accuracy,\n",
    "            'high_accuracy': high_accuracy,\n",
    "            'tracking_accuracy': tracking_accuracy\n",
    "        }\n",
    "\n",
    "# Advanced TD3-like agent for high precision control\n",
    "class PrecisionTD3Agent:\n",
    "    def __init__(self, state_size, action_size, hidden_size=64, device='cpu'):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.device = device\n",
    "        \n",
    "        # Hyperparameters tuned for high precision\n",
    "        self.gamma = 0.99  # Discount factor\n",
    "        self.tau = 0.005   # Soft update parameter\n",
    "        self.policy_noise = 0.1  # Target policy smoothing noise\n",
    "        self.noise_clip = 0.25   # Noise clip for target policy\n",
    "        self.policy_delay = 2    # Delay policy updates\n",
    "        \n",
    "        # Exploration parameters\n",
    "        self.exploration_noise = 0.2  # Initial exploration noise\n",
    "        self.noise_decay = 0.995       # Exploration noise decay\n",
    "        self.min_noise = 0.02         # Minimum exploration noise\n",
    "        \n",
    "        # Batch parameters\n",
    "        self.batch_size = 256  # Larger batch for more stable gradients\n",
    "        self.warmup = 1000     # Initial collect steps before training\n",
    "        \n",
    "        # Initialize actor and critic networks\n",
    "        self.actor = EnhancedActor(state_size, action_size, hidden_size).to(device)\n",
    "        self.actor_target = EnhancedActor(state_size, action_size, hidden_size).to(device)\n",
    "        self.actor_target.load_state_dict(self.actor.state_dict())\n",
    "        \n",
    "        self.critic = EnhancedCritic(state_size, action_size, hidden_size).to(device)\n",
    "        self.critic_target = EnhancedCritic(state_size, action_size, hidden_size).to(device)\n",
    "        self.critic_target.load_state_dict(self.critic.state_dict())\n",
    "        \n",
    "        # Optimizers\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=3e-4)\n",
    "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=3e-4)\n",
    "        \n",
    "        # Experience replay buffer with prioritized replay\n",
    "        self.memory = PrecisionReplayBuffer(\n",
    "            capacity=100000, \n",
    "            state_size=state_size,\n",
    "            action_size=action_size\n",
    "        )\n",
    "        \n",
    "        # Training statistics\n",
    "        self.total_steps = 0\n",
    "        self.policy_update_counter = 0\n",
    "        \n",
    "        # Schedule learning rate decay\n",
    "        self.lr_scheduler_actor = optim.lr_scheduler.StepLR(self.actor_optimizer, step_size=5000, gamma=0.5)\n",
    "        self.lr_scheduler_critic = optim.lr_scheduler.StepLR(self.critic_optimizer, step_size=5000, gamma=0.5)\n",
    "        \n",
    "    def select_action(self, state, add_noise=True):\n",
    "        \"\"\"Select action from policy with optional exploration noise\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Prepare state tensor\n",
    "            if isinstance(state, np.ndarray):\n",
    "                state = torch.FloatTensor(state).to(self.device).unsqueeze(0)\n",
    "            \n",
    "            # Get deterministic action from policy\n",
    "            action = self.actor(state).cpu().detach().numpy().flatten()\n",
    "            \n",
    "            # Add exploration noise if in training mode\n",
    "            if add_noise:\n",
    "                noise = np.random.normal(0, self.exploration_noise, size=self.action_size)\n",
    "                action += noise\n",
    "                \n",
    "            # Clip to valid range\n",
    "            action = np.clip(action, -1.0, 1.0)\n",
    "            \n",
    "            # Convert to scalar if action_size is 1\n",
    "            if self.action_size == 1:\n",
    "                action = float(action[0])\n",
    "                \n",
    "            return action\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Main training method implementing TD3 algorithm with improvements\"\"\"\n",
    "        # Skip during warmup phase\n",
    "        if len(self.memory) < max(self.batch_size, self.warmup):\n",
    "            return 0, 0, 0\n",
    "        \n",
    "        # Update statistics\n",
    "        self.total_steps += 1\n",
    "        \n",
    "        # Sample batch with priorities\n",
    "        states, actions, rewards, next_states, dones, indices, weights = self.memory.sample(\n",
    "            self.batch_size, prioritized=True\n",
    "        )\n",
    "        \n",
    "        # Move tensors to device\n",
    "        states = states.to(self.device)\n",
    "        actions = actions.to(self.device)\n",
    "        rewards = rewards.to(self.device)\n",
    "        next_states = next_states.to(self.device)\n",
    "        dones = dones.to(self.device)\n",
    "        weights = weights.to(self.device)\n",
    "        \n",
    "        # Get TD target\n",
    "        with torch.no_grad():\n",
    "            # Select action from target policy with noise\n",
    "            noise = torch.randn_like(actions) * self.policy_noise\n",
    "            noise = noise.clamp(-self.noise_clip, self.noise_clip)\n",
    "            \n",
    "            next_actions = self.actor_target(next_states) + noise\n",
    "            next_actions = next_actions.clamp(-1, 1)\n",
    "            \n",
    "            # Get minimum Q-value from both critics\n",
    "            target_q1, target_q2 = self.critic_target(next_states, next_actions)\n",
    "            target_q = torch.min(target_q1, target_q2)\n",
    "            \n",
    "            # Compute target with reward and discount\n",
    "            target_q = rewards + (1 - dones) * self.gamma * target_q\n",
    "        \n",
    "        # Get current Q estimates from both critics\n",
    "        current_q1, current_q2 = self.critic(states, actions)\n",
    "        \n",
    "        # Compute critic loss (weighted MSE loss for prioritized replay)\n",
    "        critic_loss1 = (weights * F.mse_loss(current_q1, target_q, reduction='none')).mean()\n",
    "        critic_loss2 = (weights * F.mse_loss(current_q2, target_q, reduction='none')).mean()\n",
    "        critic_loss = critic_loss1 + critic_loss2\n",
    "        \n",
    "        # Optimize critic\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(self.critic.parameters(), max_norm=1.0)\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        # Schedule learning rate decay\n",
    "        self.lr_scheduler_critic.step()\n",
    "        \n",
    "        # Update priorities in replay buffer\n",
    "        with torch.no_grad():\n",
    "            # Use TD error as priority\n",
    "            td_errors = torch.abs(current_q1 - target_q).cpu().numpy().flatten()\n",
    "            self.memory.update_priorities(indices, td_errors + 1e-6)  # small constant for stability\n",
    "        \n",
    "        # Delayed policy updates\n",
    "        actor_loss = torch.tensor(0.0)\n",
    "        \n",
    "        if self.total_steps % self.policy_delay == 0:\n",
    "            # Compute actor loss - maximize Q1 value\n",
    "            actor_loss = -self.critic.q1(states, self.actor(states)).mean()\n",
    "            \n",
    "            # Optimize actor\n",
    "            self.actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            nn.utils.clip_grad_norm_(self.actor.parameters(), max_norm=1.0)\n",
    "            self.actor_optimizer.step()\n",
    "            \n",
    "            # Schedule learning rate decay\n",
    "            self.lr_scheduler_actor.step()\n",
    "            \n",
    "            # Soft update target networks\n",
    "            self._soft_update(self.actor, self.actor_target)\n",
    "            self._soft_update(self.critic, self.critic_target)\n",
    "            \n",
    "            # Update counter\n",
    "            self.policy_update_counter += 1\n",
    "            \n",
    "            # Decay exploration noise\n",
    "            self.exploration_noise = max(\n",
    "                self.min_noise, \n",
    "                self.exploration_noise * self.noise_decay\n",
    "            )\n",
    "        \n",
    "        return float(critic_loss.item()), float(actor_loss.item()), float(self.exploration_noise)\n",
    "    \n",
    "    def _soft_update(self, source, target):\n",
    "        \"\"\"Soft update target network parameters\"\"\"\n",
    "        for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "            target_param.data.copy_(\n",
    "                target_param.data * (1.0 - self.tau) + param.data * self.tau\n",
    "            )\n",
    "    \n",
    "    def save(self, path):\n",
    "        \"\"\"Save model weights\"\"\"\n",
    "        torch.save({\n",
    "            'actor': self.actor.state_dict(),\n",
    "            'critic': self.critic.state_dict(),\n",
    "            'actor_target': self.actor_target.state_dict(),\n",
    "            'critic_target': self.critic_target.state_dict(),\n",
    "            'actor_optimizer': self.actor_optimizer.state_dict(),\n",
    "            'critic_optimizer': self.critic_optimizer.state_dict(),\n",
    "            'exploration_noise': self.exploration_noise\n",
    "        }, path)\n",
    "        \n",
    "    def load(self, path):\n",
    "        \"\"\"Load model weights\"\"\"\n",
    "        checkpoint = torch.load(path, map_location=self.device)\n",
    "        self.actor.load_state_dict(checkpoint['actor'])\n",
    "        self.critic.load_state_dict(checkpoint['critic'])\n",
    "        self.actor_target.load_state_dict(checkpoint['actor_target'])\n",
    "        self.critic_target.load_state_dict(checkpoint['critic_target'])\n",
    "        self.actor_optimizer.load_state_dict(checkpoint['actor_optimizer'])\n",
    "        self.critic_optimizer.load_state_dict(checkpoint['critic_optimizer'])\n",
    "        self.exploration_noise = checkpoint['exploration_noise']\n",
    "\n",
    "# Generate complex temperature profile with challenging segments\n",
    "def generate_complex_profile(length=5000):\n",
    "    \"\"\"Generate a complex temperature profile with various challenging segments\"\"\"\n",
    "    data = np.zeros((length, 1))\n",
    "    \n",
    "    # Segment 1: Startup (0-500)\n",
    "    data[:500] = 0.25  # 45°C\n",
    "    \n",
    "    # Segment 2: First ramp (500-1000) - slow ramp\n",
    "    for i in range(500, 1000):\n",
    "        progress = (i - 500) / 500\n",
    "        data[i] = 0.25 + progress * 0.35  # 45°C to 60°C\n",
    "    \n",
    "    # Segment 3: First hold (1000-1300) with small oscillations\n",
    "    for i in range(1000, 1300):\n",
    "        data[i] = 0.6 + np.sin((i-1000) * 0.1) * 0.02  # Oscillate around 60°C\n",
    "    \n",
    "    # Segment 4: Quick ramp up (1300-1500) - steep change\n",
    "    for i in range(1300, 1500):\n",
    "        progress = (i - 1300) / 200\n",
    "        data[i] = 0.6 + progress * 0.3  # 60°C to 90°C\n",
    "    \n",
    "    # Segment 5: Critical hold (1500-2000) - requires precision\n",
    "    for i in range(1500, 2000):\n",
    "        data[i] = 0.9 + np.sin((i-1500) * 0.05) * 0.01  # Precision hold at 90°C\n",
    "    \n",
    "    # Segment 6: Controlled step down (2000-2300) - smaller steps\n",
    "    for i in range(2000, 2300):\n",
    "        if i < 2100:\n",
    "            data[i] = 0.9\n",
    "        elif i < 2200:\n",
    "            data[i] = 0.85\n",
    "        else:\n",
    "            data[i] = 0.8  # Step down to 80°C\n",
    "    \n",
    "    # Segment 7: Gradual cool (2300-3000)\n",
    "    for i in range(2300, 3000):\n",
    "        progress = (i - 2300) / 700\n",
    "        data[i] = 0.8 - progress * 0.3  # 80°C to 50°C\n",
    "    \n",
    "    # Segment 8: Complex pattern (3000-4000) - sinusoidal changes\n",
    "    for i in range(3000, 4000):\n",
    "        normalized_i = (i - 3000) / 1000 * 2 * np.pi\n",
    "        data[i] = 0.5 + 0.2 * np.sin(normalized_i * 2) + 0.1 * np.sin(normalized_i * 5)\n",
    "    \n",
    "    # Segment 9: Final cooldown (4000-end)\n",
    "    for i in range(4000, length):\n",
    "        progress = min(1.0, (i - 4000) / 800)\n",
    "        data[i] = 0.5 - progress * 0.4  # 50°C down to 10°C\n",
    "    \n",
    "    # Add some noise to make it realistic\n",
    "    data += np.random.normal(0, 0.005, size=data.shape)\n",
    "    \n",
    "    # Clip to valid range [0, 1]\n",
    "    data = np.clip(data, 0, 1)\n",
    "    \n",
    "    return data.astype(np.float32)\n",
    "\n",
    "# Advanced training function with precision focus and analytics\n",
    "def precision_train(env, agent, max_steps=100000, eval_interval=5000, \n",
    "                   early_stop_threshold=0.98, progress_bar=True):\n",
    "    \"\"\"Train the agent with high precision focus\n",
    "    \n",
    "    Args:\n",
    "        env: Control environment\n",
    "        agent: TD3 agent\n",
    "        max_steps: Maximum training steps\n",
    "        eval_interval: Steps between evaluation runs\n",
    "        early_stop_threshold: Accuracy threshold for early stopping\n",
    "        progress_bar: Whether to show progress bar\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training metrics\n",
    "    rewards_history = []\n",
    "    critic_losses = []\n",
    "    actor_losses = []\n",
    "    accuracy_history = []\n",
    "    high_accuracy_history = []\n",
    "    tracking_errors = []\n",
    "    \n",
    "    # Best model tracking\n",
    "    best_high_accuracy = 0.0\n",
    "    best_step = 0\n",
    "    \n",
    "    # Initial state\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    episode_reward = 0.0\n",
    "    episode_steps = 0\n",
    "    episode = 1\n",
    "    \n",
    "    # Progress tracking\n",
    "    total_steps = 0\n",
    "    \n",
    "    # Create progress bar if requested\n",
    "    if progress_bar:\n",
    "        pbar = tqdm(total=max_steps, desc=\"Training\")\n",
    "    \n",
    "    while total_steps < max_steps:\n",
    "        # Select action with exploration noise\n",
    "        action = agent.select_action(state, add_noise=True)\n",
    "        \n",
    "        # Step environment\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        # Store transition\n",
    "        # Use error magnitude as priority for replay buffer\n",
    "        priority = float(info['abs_error']) + 0.1  # Add small constant for stability\n",
    "        agent.memory.add(state, action, reward, next_state, done, priority)\n",
    "        \n",
    "        # Update state\n",
    "        state = next_state\n",
    "        episode_reward += float(reward)\n",
    "        episode_steps += 1\n",
    "        total_steps += 1\n",
    "        \n",
    "        # Train agent\n",
    "        critic_loss, actor_loss, noise = agent.train()\n",
    "        \n",
    "        # Track metrics (less frequently to save compute)\n",
    "        if total_steps % 10 == 0:\n",
    "            critic_losses.append(critic_loss)\n",
    "            actor_losses.append(actor_loss)\n",
    "            accuracy_history.append(info['accuracy'])\n",
    "            high_accuracy_history.append(info['high_accuracy'])\n",
    "            tracking_errors.append(info['abs_error'])\n",
    "            rewards_history.append(reward)\n",
    "        \n",
    "        # Reset if episode is done\n",
    "        if done:\n",
    "            if progress_bar:\n",
    "                # Update progress bar\n",
    "                pbar.set_postfix({\n",
    "                    'episode': episode,\n",
    "                    'reward': f\"{episode_reward:.2f}\",\n",
    "                    'acc': f\"{info['accuracy']*100:.2f}%\",\n",
    "                    'high_acc': f\"{info['high_accuracy']*100:.2f}%\",\n",
    "                    'noise': f\"{agent.exploration_noise:.3f}\"\n",
    "                })\n",
    "            \n",
    "            # Reset environment\n",
    "            state = env.reset()\n",
    "            done = False\n",
    "            episode_reward = 0.0\n",
    "            episode_steps = 0\n",
    "            episode += 1\n",
    "        \n",
    "        # Periodic evaluation\n",
    "        if total_steps % eval_interval == 0:\n",
    "            # Run evaluation\n",
    "            eval_results = precision_evaluate(env, agent)\n",
    "            \n",
    "            # Check for best model\n",
    "            if eval_results['high_accuracy'] > best_high_accuracy:\n",
    "                best_high_accuracy = eval_results['high_accuracy']\n",
    "                best_step = total_steps\n",
    "                \n",
    "                # Save best model\n",
    "                agent.save('best_precision_controller.pth')\n",
    "                \n",
    "                # Print best model info\n",
    "                print(f\"\\nNew best model at step {total_steps}:\")\n",
    "                print(f\"Standard Accuracy: {eval_results['accuracy']*100:.2f}%\")\n",
    "                print(f\"High Accuracy: {eval_results['high_accuracy']*100:.2f}%\")\n",
    "                print(f\"RMSE: {eval_results['rmse']:.4f}\")\n",
    "            \n",
    "            # Early stopping check\n",
    "            if eval_results['high_accuracy'] >= early_stop_threshold:\n",
    "                print(f\"\\nEarly stopping at step {total_steps}: \"\n",
    "                      f\"High accuracy threshold {early_stop_threshold*100:.1f}% reached!\")\n",
    "                break\n",
    "        \n",
    "        # Update progress bar\n",
    "        if progress_bar:\n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Training complete\n",
    "    if progress_bar:\n",
    "        pbar.close()\n",
    "    \n",
    "    # Calculate training time\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Load best model\n",
    "    agent.load('best_precision_controller.pth')\n",
    "    \n",
    "    # Final evaluation\n",
    "    final_eval = precision_evaluate(env, agent)\n",
    "    \n",
    "    print(f\"\\nTraining completed in {training_time:.2f} seconds\")\n",
    "    print(f\"Best model achieved at step {best_step}:\")\n",
    "    print(f\"Final Standard Accuracy: {final_eval['accuracy']*100:.2f}%\")\n",
    "    print(f\"Final High Accuracy: {final_eval['high_accuracy']*100:.2f}%\")\n",
    "    print(f\"Final RMSE: {final_eval['rmse']:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'rewards': rewards_history,\n",
    "        'critic_losses': critic_losses,\n",
    "        'actor_losses': actor_losses,\n",
    "        'accuracy_history': accuracy_history,\n",
    "        'high_accuracy_history': high_accuracy_history,\n",
    "        'tracking_errors': tracking_errors,\n",
    "        'training_time': training_time,\n",
    "        'best_step': best_step,\n",
    "        'final_accuracy': final_eval['accuracy'],\n",
    "        'final_high_accuracy': final_eval['high_accuracy'],\n",
    "        'final_rmse': final_eval['rmse']\n",
    "    }\n",
    "\n",
    "# Precision evaluation function\n",
    "def precision_evaluate(env, agent, episodes=1, verbose=False):\n",
    "    \"\"\"Evaluate the agent with high precision metrics\"\"\"\n",
    "    temperatures = []\n",
    "    setpoints = []\n",
    "    errors = []\n",
    "    tracking_accuracies = []\n",
    "    actions = []\n",
    "    \n",
    "    total_steps = 0\n",
    "    accurate_steps = 0\n",
    "    high_accurate_steps = 0\n",
    "    \n",
    "    for _ in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            # Select action without exploration noise\n",
    "            action = agent.select_action(state, add_noise=False)\n",
    "            \n",
    "            # Step environment\n",
    "            next_state, _, done, info = env.step(action)\n",
    "            \n",
    "            # Track metrics\n",
    "            temperatures.append(info['temperature'])\n",
    "            setpoints.append(info['setpoint'])\n",
    "            errors.append(info['abs_error'])\n",
    "            tracking_accuracies.append(info['tracking_accuracy'])\n",
    "            \n",
    "            if isinstance(action, (int, float)):\n",
    "                actions.append(float(action))\n",
    "            else:\n",
    "                actions.append(float(action[0]) if hasattr(action, '__len__') else float(action))\n",
    "            \n",
    "            # Update counters\n",
    "            total_steps += 1\n",
    "            if info['abs_error'] < 0.05:  # 5% error threshold\n",
    "                accurate_steps += 1\n",
    "            if info['abs_error'] < 0.01:  # 1% error threshold\n",
    "                high_accurate_steps += 1\n",
    "            \n",
    "            # Update state\n",
    "            state = next_state\n",
    "    \n",
    "    # Calculate metrics\n",
    "    temperatures = np.array(temperatures)\n",
    "    setpoints = np.array(setpoints)\n",
    "    errors = np.array(errors)\n",
    "    tracking_accuracies = np.array(tracking_accuracies)\n",
    "    actions = np.array(actions)\n",
    "    \n",
    "    # Calculate standard and high precision accuracy\n",
    "    accuracy = accurate_steps / total_steps if total_steps > 0 else 0\n",
    "    high_accuracy = high_accurate_steps / total_steps if total_steps > 0 else 0\n",
    "    \n",
    "    # Calculate RMSE and other statistics\n",
    "    rmse = np.sqrt(np.mean(np.square(errors)))\n",
    "    max_error = np.max(errors)\n",
    "    mean_error = np.mean(errors)\n",
    "    \n",
    "    # Calculate control effort and smoothness\n",
    "    mean_abs_action = np.mean(np.abs(actions))\n",
    "    if len(actions) > 1:\n",
    "        action_changes = np.abs(np.diff(actions))\n",
    "        mean_action_change = np.mean(action_changes)\n",
    "    else:\n",
    "        mean_action_change = 0.0\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Evaluation Results:\")\n",
    "        print(f\"Standard Accuracy (5%): {accuracy*100:.2f}%\")\n",
    "        print(f\"High Accuracy (1%): {high_accuracy*100:.2f}%\")\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"Mean Error: {mean_error:.4f}\")\n",
    "        print(f\"Max Error: {max_error:.4f}\")\n",
    "        print(f\"Mean Action Magnitude: {mean_abs_action:.4f}\")\n",
    "        print(f\"Mean Action Change: {mean_action_change:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'temperatures': temperatures,\n",
    "        'setpoints': setpoints,\n",
    "        'errors': errors,\n",
    "        'tracking_accuracies': tracking_accuracies,\n",
    "        'actions': actions,\n",
    "        'accuracy': accuracy,\n",
    "        'high_accuracy': high_accuracy,\n",
    "        'rmse': rmse,\n",
    "        'mean_error': mean_error,\n",
    "        'max_error': max_error,\n",
    "        'mean_abs_action': mean_abs_action,\n",
    "        'mean_action_change': mean_action_change\n",
    "    }\n",
    "\n",
    "# Enhanced visualization with accuracy details\n",
    "def visualize_precision_control(results, training_metrics=None, save_path=None):\n",
    "    \"\"\"Create comprehensive visualization with accuracy metrics\"\"\"\n",
    "    plt.style.use('ggplot')  # Nicer style\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    \n",
    "    # Main temperature plot\n",
    "    ax1 = plt.subplot2grid((3, 2), (0, 0), colspan=2)\n",
    "    \n",
    "    # Get data\n",
    "    temperatures = results['temperatures']\n",
    "    setpoints = results['setpoints']\n",
    "    time_steps = np.arange(len(temperatures))\n",
    "    \n",
    "    # Plot temperatures and setpoints\n",
    "    ax1.plot(time_steps, setpoints, 'r--', linewidth=2, label='Target Temperature')\n",
    "    ax1.plot(time_steps, temperatures, 'b-', linewidth=1.5, label='Actual Temperature')\n",
    "    \n",
    "    # Shade accuracy regions\n",
    "    for i, err in enumerate(results['errors']):\n",
    "        if err < 0.01:  # High accuracy zone (<1%)\n",
    "            ax1.axvspan(i, i+1, alpha=0.2, color='green', lw=0)\n",
    "        elif err < 0.05:  # Standard accuracy zone (<5%)\n",
    "            ax1.axvspan(i, i+1, alpha=0.1, color='green', lw=0)\n",
    "    \n",
    "    # Add plot details\n",
    "    ax1.set_title('High-Precision Reactor Temperature Control', fontsize=16)\n",
    "    ax1.set_xlabel('Time Steps', fontsize=12)\n",
    "    ax1.set_ylabel('Temperature (°C)', fontsize=12)\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add accuracy text\n",
    "    accuracy_text = (\n",
    "        f\"Standard Accuracy (5%): {results['accuracy']*100:.2f}%\\n\"\n",
    "        f\"High Accuracy (1%): {results['high_accuracy']*100:.2f}%\\n\"\n",
    "        f\"RMSE: {results['rmse']:.4f}\"\n",
    "    )\n",
    "    ax1.text(0.02, 0.02, accuracy_text, transform=ax1.transAxes, \n",
    "             bbox=dict(facecolor='white', alpha=0.8), fontsize=12)\n",
    "    \n",
    "    # Plot absolute error\n",
    "    ax2 = plt.subplot2grid((3, 2), (1, 0))\n",
    "    ax2.plot(time_steps, results['errors'], 'r-', linewidth=1.5)\n",
    "    ax2.axhline(y=0.05, color='g', linestyle='--', alpha=0.7, label='5% Error')\n",
    "    ax2.axhline(y=0.01, color='g', linestyle='-', alpha=0.7, label='1% Error')\n",
    "    ax2.set_title('Tracking Error', fontsize=14)\n",
    "    ax2.set_xlabel('Time Steps', fontsize=12)\n",
    "    ax2.set_ylabel('Error (normalized)', fontsize=12)\n",
    "    ax2.set_ylim(bottom=0)  # Start from 0\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot control actions\n",
    "    ax3 = plt.subplot2grid((3, 2), (1, 1))\n",
    "    ax3.plot(time_steps, results['actions'], 'g-', linewidth=1.5)\n",
    "    ax3.set_title('Control Actions', fontsize=14)\n",
    "    ax3.set_xlabel('Time Steps', fontsize=12)\n",
    "    ax3.set_ylabel('Control Signal', fontsize=12)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot training metrics if available\n",
    "    if training_metrics:\n",
    "        # Accuracy progress during training\n",
    "        ax4 = plt.subplot2grid((3, 2), (2, 0))\n",
    "        steps = np.arange(len(training_metrics['high_accuracy_history']))\n",
    "        ax4.plot(steps, np.array(training_metrics['accuracy_history'])*100, 'b-', label='Standard (5%)')\n",
    "        ax4.plot(steps, np.array(training_metrics['high_accuracy_history'])*100, 'g-', label='High (1%)')\n",
    "        ax4.set_title('Training Accuracy Progress', fontsize=14)\n",
    "        ax4.set_xlabel('Training Steps (x10)', fontsize=12)\n",
    "        ax4.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "        ax4.legend(fontsize=10)\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Loss values during training\n",
    "        ax5 = plt.subplot2grid((3, 2), (2, 1))\n",
    "        # Smooth losses for better visualization\n",
    "        window = min(100, len(training_metrics['critic_losses'])//10)\n",
    "        if window > 0:\n",
    "            critic_losses = np.convolve(\n",
    "                training_metrics['critic_losses'], \n",
    "                np.ones(window)/window, \n",
    "                mode='valid'\n",
    "            )\n",
    "            actor_losses = np.convolve(\n",
    "                training_metrics['actor_losses'], \n",
    "                np.ones(window)/window, \n",
    "                mode='valid'\n",
    "            )\n",
    "            ax5.plot(critic_losses, 'r-', label='Critic Loss')\n",
    "            ax5.plot(actor_losses, 'b-', label='Actor Loss')\n",
    "        else:\n",
    "            ax5.plot(training_metrics['critic_losses'], 'r-', label='Critic Loss')\n",
    "            ax5.plot(training_metrics['actor_losses'], 'b-', label='Actor Loss')\n",
    "            \n",
    "        ax5.set_title('Training Losses (Smoothed)', fontsize=14)\n",
    "        ax5.set_xlabel('Training Steps', fontsize=12)\n",
    "        ax5.set_ylabel('Loss', fontsize=12)\n",
    "        ax5.legend(fontsize=10)\n",
    "        ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure if path provided\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Visualization saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    print(\"Starting High-Accuracy Reactor Temperature Controller...\")\n",
    "    \n",
    "    # Configure torch for fast execution\n",
    "    torch.set_num_threads(4)  # Limit threads for better hardware utilization\n",
    "    \n",
    "    # Use CUDA if available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Generate complex temperature profile\n",
    "    print(\"Generating complex reactor temperature profile...\")\n",
    "    reference_data = generate_complex_profile()\n",
    "    print(f\"Generated reference trajectory with {len(reference_data)} points\")\n",
    "    \n",
    "    # Create high-precision environment\n",
    "    window_size = 20  # Larger window for better prediction\n",
    "    \n",
    "    env = PrecisionControlEnvironment(\n",
    "        reference_trajectory=reference_data,\n",
    "        window_size=window_size,\n",
    "        dt=0.1,\n",
    "        history_overlap=0.5,  # Keep 50% of history between steps\n",
    "        reward_shaping=True  # Use shaped rewards for better learning\n",
    "    )\n",
    "    \n",
    "    # Create agent with enhanced state representation\n",
    "    # Each state includes history of temps, setpoints, errors and controls\n",
    "    state_size = window_size * 4  # 4 history components in state vector\n",
    "    \n",
    "    agent = PrecisionTD3Agent(\n",
    "        state_size=state_size,\n",
    "        action_size=1,  # Single control signal\n",
    "        hidden_size=64,  # Larger network for more precision\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Train with precision focus\n",
    "    print(\"Starting precision training...\")\n",
    "    training_metrics = precision_train(\n",
    "        env=env,\n",
    "        agent=agent,\n",
    "        max_steps=50000,  # More steps for higher precision\n",
    "        eval_interval=5000,\n",
    "        early_stop_threshold=0.95,  # Stop when reaching 95% high accuracy\n",
    "        progress_bar=True  # Show progress bar during training\n",
    "    )\n",
    "    \n",
    "    # Evaluate final controller performance\n",
    "    print(\"\\nEvaluating final controller performance...\")\n",
    "    eval_results = precision_evaluate(env, agent, verbose=True)\n",
    "    \n",
    "    # Visualize results\n",
    "    visualize_precision_control(\n",
    "        results=eval_results,\n",
    "        training_metrics=training_metrics,\n",
    "        save_path='high_precision_controller.png'\n",
    "    )\n",
    "    \n",
    "    print(\"\\nHigh-Accuracy Reactor Temperature Controller completed!\")\n",
    "    print(f\"Final Standard Accuracy (5%): {eval_results['accuracy']*100:.2f}%\")\n",
    "    print(f\"Final High Accuracy (1%): {eval_results['high_accuracy']*100:.2f}%\")\n",
    "    print(f\"RMSE: {eval_results['rmse']:.4f}\")\n",
    "    print(f\"Training time: {training_metrics['training_time']:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b96566-c897-4c04-a245-ef495d046ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
